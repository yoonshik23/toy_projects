{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 csv_data\\데이터 분석과제 (1)\\GTW07-034_210801.csv\n",
      "1 csv_data\\데이터 분석과제 (1)\\GTW07-034_210802.csv\n",
      "2 csv_data\\데이터 분석과제 (1)\\GTW07-034_210803.csv\n",
      "3 csv_data\\데이터 분석과제 (1)\\GTW07-034_210804.csv\n",
      "4 csv_data\\데이터 분석과제 (1)\\GTW07-034_210805.csv\n",
      "5 csv_data\\데이터 분석과제 (1)\\GTW07-034_210806.csv\n",
      "6 csv_data\\데이터 분석과제 (1)\\GTW07-034_210807.csv\n",
      "7 csv_data\\데이터 분석과제 (1)\\GTW07-034_210808.csv\n",
      "8 csv_data\\데이터 분석과제 (1)\\GTW07-034_210809.csv\n",
      "9 csv_data\\데이터 분석과제 (1)\\GTW07-034_210810.csv\n",
      "10 csv_data\\데이터 분석과제 (1)\\GTW07-034_210811.csv\n",
      "11 csv_data\\데이터 분석과제 (1)\\GTW07-034_210812.csv\n",
      "12 csv_data\\데이터 분석과제 (1)\\GTW07-034_210813.csv\n",
      "13 csv_data\\데이터 분석과제 (1)\\GTW07-034_210814.csv\n",
      "14 csv_data\\데이터 분석과제 (1)\\GTW07-034_210815.csv\n",
      "15 csv_data\\데이터 분석과제 (1)\\GTW07-034_210816.csv\n",
      "16 csv_data\\데이터 분석과제 (1)\\GTW07-034_210817.csv\n",
      "17 csv_data\\데이터 분석과제 (1)\\GTW07-034_210818.csv\n",
      "18 csv_data\\데이터 분석과제 (1)\\GTW07-034_210819.csv\n",
      "19 csv_data\\데이터 분석과제 (1)\\GTW07-034_210820.csv\n",
      "20 csv_data\\데이터 분석과제 (1)\\GTW07-034_210821.csv\n",
      "21 csv_data\\데이터 분석과제 (1)\\GTW07-034_210822.csv\n",
      "22 csv_data\\데이터 분석과제 (1)\\GTW07-034_210823.csv\n",
      "23 csv_data\\데이터 분석과제 (1)\\GTW07-034_210824.csv\n",
      "24 csv_data\\데이터 분석과제 (1)\\GTW07-034_210825.csv\n",
      "25 csv_data\\데이터 분석과제 (1)\\GTW07-034_210826.csv\n",
      "26 csv_data\\데이터 분석과제 (1)\\GTW07-034_210827.csv\n",
      "27 csv_data\\데이터 분석과제 (1)\\GTW07-034_210828.csv\n",
      "28 csv_data\\데이터 분석과제 (1)\\GTW07-034_210829.csv\n",
      "29 csv_data\\데이터 분석과제 (1)\\GTW07-034_210830.csv\n",
      "30 csv_data\\데이터 분석과제 (1)\\GTW07-034_210831.csv\n",
      "31 csv_data\\데이터 분석과제 (1)\\GTW07-034_210901.csv\n",
      "32 csv_data\\데이터 분석과제 (1)\\GTW07-034_210902.csv\n",
      "33 csv_data\\데이터 분석과제 (1)\\GTW07-034_210903.csv\n",
      "34 csv_data\\데이터 분석과제 (1)\\GTW07-034_210904.csv\n"
     ]
    }
   ],
   "source": [
    "path = glob.glob(r'csv_data\\데이터 분석과제 (1)\\*')\n",
    "for i,j in enumerate(path):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df =pd.read_csv(path[0]).iloc[:,:83]\n",
    "for i in range(1, 31):\n",
    "    tmp_df = tmp_df.append(pd.read_csv(path[i]).iloc[:,:83], ignore_index=True)\n",
    "for i in range(33, 35):\n",
    "    tmp_df = tmp_df.append(pd.read_csv(path[i]).iloc[:,:83], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tmp_df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 각 column별 자료형 확인\n",
    "for j,i in enumerate(list(df)):\n",
    "    print(j, i, df[i].dtype)\n",
    "# 몇몇 변수가 null값으로 인해 object 변수로 입력돼있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용하지 않는 변수 제거\n",
    "df = df.drop(axis='columns', columns=[' X_PEAK', ' X_PEAK_ALARM', ' X_RMS', ' X_RMS_ALARM'\n",
    "                                     , ' Y_PEAK', ' Y_PEAK_ALARM', ' Y_RMS', ' Y_RMS_ALARM'\n",
    "                                     , ' Z_PEAK', ' Z_PEAK_ALARM', ' Z_RMS', ' Z_RMS_ALARM'\n",
    "                                     , 'MEASR_YYYY', 'MEASR_MM', 'MEASR_DD', 'MEASR_HH'])\n",
    "# null값으로 인해 object 변수로 입력된 것을 float으로 변환.\n",
    "for i in range(11, 23, 2):\n",
    "    df[list(df)[i]] = df[list(df)[i]].astype(float)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 자료형 다시 확인\n",
    "for j,i in enumerate(list(df)):\n",
    "    print(j, i, df[i].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEASR_DTTM 컬럼을 시간 자료형으로 변경 후 시간 순으로 데이터 정렬\n",
    "df['MEASR_DTTM'] = pd.to_datetime(df['MEASR_DTTM'])\n",
    "df = df.sort_values(by=['MEASR_DTTM'])\n",
    "df = df.reset_index(drop=True)\n",
    "# 앞에 sensor_id 등 제거\n",
    "df = df.iloc[:,6:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 변수명 앞에 띄어쓰기 없애기\n",
    "col = []\n",
    "for i in range(len(list(df))):\n",
    "    col.append(list(df)[i].split(' ')[-1])\n",
    "df.columns= col\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021-08-29  5:22:00 AM\n",
    "# 2021-09-03  9:35:00 AM 전조 시점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "df['STATUS'] = '정상' #  label column 생성\n",
    "df.loc[(df['MEASR_DTTM']>= pd.to_datetime('2021-08-29  5:22:00'))&(df['MEASR_DTTM']<= pd.to_datetime('2021-09-03  9:35:00')),'STATUS']='전조'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df['MEASR_DTTM'], df.iloc[:,np.arange(1,60,2)], df['STATUS']], axis=1)\n",
    "df.to_csv(r'data\\data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여기부터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'data\\data.csv',index_col=0)\n",
    "df['MEASR_DTTM'] =pd.to_datetime(df['MEASR_DTTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import  stats\n",
    "# 모평균 차이 검정\n",
    "\n",
    "# t-test(정규성 만족 할 때)\n",
    "for i in range(len(list(df))-2):\n",
    "    print(list(df)[i+1],' ', end='')\n",
    "    print(stats.ttest_ind(df[df['STATUS']=='정상'].iloc[:,i+1], df[df['STATUS']!='정상'].iloc[:,i+1], equal_var=True))\n",
    "#     print(stats.ttest_ind(df_list[i][df_list[i]['Y']==1].iloc[:,-2], df_list[i][df_list[i]['Y']==0].iloc[:,-2], equal_var=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모평균 차이 검정\n",
    "\n",
    "# 정규성 만족 안하는 경우 (Mann-Whitney U test)\n",
    "for i in range(len(list(df))-2):\n",
    "    print(list(df)[i+1],' ', end='')\n",
    "    print(stats.mannwhitneyu(df[df['STATUS']=='정상'].iloc[:,i+1], df[df['STATUS']!='정상'].iloc[:,i+1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 등분산 검정\n",
    "\n",
    "def f_test(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    f = np.var(x, ddof=1) / np.var(y, ddof=1)  # calculate F test statistic\n",
    "    dfn = x.size - 1  # define degrees of freedom numerator\n",
    "    dfd = y.size - 1  # define degrees of freedom denominator\n",
    "    p = 2 * min(stats.f.cdf(f, dfn, dfd), 1-stats.f.cdf(f, dfn, dfd)) # find p-value of F test statistic\n",
    "    return f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# f-test\n",
    "for i in range(len(list(df))-2):\n",
    "    print(list(df)[i+1],' ', end='')\n",
    "    print(f_test(df[df['STATUS']=='정상'].iloc[:,i+1], df[df['STATUS']!='정상'].iloc[:,i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bartlett’s test, Fligner-Killeen test, Levene test\n",
    "for i in range(len(list(df))-2):\n",
    "    print(list(df)[i+1],' ', end='')\n",
    "    a = df[df['STATUS']=='정상'].iloc[:,i+1]\n",
    "    b = df[df['STATUS']!='정상'].iloc[:,i+1]\n",
    "    print(stats.bartlett(a, b), stats.fligner(a, b), stats.levene(a, b), sep = '\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[df['MEASR_DTTM']<pd.to_datetime('2021-08-27 00:00:00')]\n",
    "test_data = df[df['MEASR_DTTM']>=pd.to_datetime('2021-08-27 00:00:00')]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "isol = IsolationForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isol.fit(train_data.iloc[:,21:31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(list(df))):\n",
    "    print(i, list(df)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "isol_score = df[['MEASR_DTTM', 'STATUS']].copy()\n",
    "isol_score['SCORE']= isol.score_samples(df.iloc[:,21:31])*-1\n",
    "isol_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "import numpy as np\n",
    "nboot = 100\n",
    "alpha=0.0001 # 백분위 기준 이상치가 1%되게 threshold 설정한다는 의미\n",
    "threshold_series = isol_score[isol_score['MEASR_DTTM']<train_test_split_point]['SCORE']\n",
    "\n",
    "bootsam = np.random.choice(threshold_series, size=len(threshold_series) * nboot, replace=True, p=None)\n",
    "bootsam.shape = (nboot, len(threshold_series))\n",
    "\n",
    "isol_threshold  = np.mean(np.percentile(bootsam, q=(1 - alpha) * 100, axis=1))\n",
    "isol_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = isol_threshold\n",
    "# threshold =0.746\n",
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "import plotly.express as px\n",
    "plot_df = isol_score.copy()\n",
    "\n",
    "\n",
    "# threshold 아래부분 sampling해서 그래프 용량 줄이기\n",
    "if len(plot_df) > 100000:\n",
    "    tmp = plot_df[plot_df['SCORE'] < threshold].sort_values(by='SCORE', ascending = False).copy()\n",
    "    tmp = tmp[:100000]\n",
    "    plot_df = pd.concat((tmp, plot_df[plot_df['SCORE']>=threshold]))\n",
    "    plot_df = plot_df.sort_values('MEASR_DTTM')\n",
    "\n",
    "\n",
    "plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "fig.add_vline(x=train_test_split_point2\n",
    "                  , line_dash=\"dash\"\n",
    "                 , annotation_text = 'Test 구간'\n",
    "    #               , line_color=\"red\"\n",
    "                 )\n",
    "fig.add_hrect(\n",
    "    y0=threshold, \n",
    "    y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "    annotation_text = '정상구간',\n",
    "    fillcolor=\"green\", opacity=0.2)\n",
    "fig.show()\n",
    "\n",
    "tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "print('test set에서 false 경고: ', len(tmp), 'test set에서 true 경고: ', len(tmp2))\n",
    "print('train set에서 false 경고: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15분 내 3회경고시 알람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timedel = 15 # 몇분 이내에 3회이상 경고 떠야 알람 울릴 것인지\n",
    "cutoff = 3 # 15분 이내에 몇개 이상일 때알람 울릴 것인지\n",
    "alarm_df = isol_score.copy()\n",
    "alarm_df['ALARM'] = False\n",
    "for i in np.where(alarm_df['SCORE'] > threshold)[0]:\n",
    "    tmp = alarm_df[(alarm_df['MEASR_DTTM']<alarm_df.iloc[i,0])&(alarm_df['MEASR_DTTM']>=alarm_df.iloc[i,0]-datetime.timedelta(minutes=timedel))]\n",
    "    if len(tmp[tmp['SCORE']>threshold])>cutoff:\n",
    "        alarm_df.iloc[i, -1] = True\n",
    "\n",
    "tmp = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = alarm_df[(alarm_df['ALARM']==True)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]      \n",
    "print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "print('train set에서 false 알람: ', len(tmp3))\n",
    "start =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "if len(tmp2) >0:\n",
    "    start = tmp2.iloc[0,0]\n",
    "    print('가짜알람비율: ',len(tmp)/(len(tmp)+len(tmp2)))\n",
    "else:\n",
    "    print('알람없음.')\n",
    "sstart =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "end = alarm_df[alarm_df['STATUS']=='전조'].iloc[-1,0]\n",
    "\n",
    "print('최초알람시점 비율',(end-start)/(end-sstart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y 만 사용한 isol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isol2 = IsolationForest()\n",
    "isol2.fit(train_data.iloc[:,11:21])\n",
    "isol_score2 = df[['MEASR_DTTM', 'STATUS']].copy()\n",
    "isol_score2['SCORE']= isol2.score_samples(df.iloc[:,11:21])*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "import numpy as np\n",
    "nboot = 100\n",
    "alpha=0.0001 # 백분위 기준 이상치가 1%되게 threshold 설정한다는 의미\n",
    "threshold_series = isol_score2[isol_score2['MEASR_DTTM']<train_test_split_point]['SCORE']\n",
    "\n",
    "bootsam = np.random.choice(threshold_series, size=len(threshold_series) * nboot, replace=True, p=None)\n",
    "bootsam.shape = (nboot, len(threshold_series))\n",
    "\n",
    "isol_threshold2  = np.mean(np.percentile(bootsam, q=(1 - alpha) * 100, axis=1))\n",
    "isol_threshold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = isol_threshold2\n",
    "# threshold =0.74865\n",
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "import plotly.express as px\n",
    "plot_df = isol_score2.copy()\n",
    "\n",
    "\n",
    "# threshold 아래부분 sampling해서 그래프 용량 줄이기\n",
    "if len(plot_df) > 100000:\n",
    "    tmp = plot_df[plot_df['SCORE'] < threshold].sort_values(by='SCORE', ascending = False).copy()\n",
    "    tmp = tmp[:100000]\n",
    "    plot_df = pd.concat((tmp, plot_df[plot_df['SCORE']>=threshold]))\n",
    "    plot_df = plot_df.sort_values('MEASR_DTTM')\n",
    "\n",
    "plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "fig.add_vline(x=train_test_split_point2\n",
    "                  , line_dash=\"dash\"\n",
    "                 , annotation_text = 'Test 구간'\n",
    "    #               , line_color=\"red\"\n",
    "                 )\n",
    "fig.add_hrect(\n",
    "    y0=threshold, \n",
    "    y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "    annotation_text = '정상구간',\n",
    "    fillcolor=\"green\", opacity=0.2)\n",
    "fig.show()\n",
    "\n",
    "tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "print('test set에서 false 경고: ', len(tmp), 'test set에서 true 경고: ', len(tmp2))\n",
    "print('train set에서 false 경고: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timedel = 15 # 몇분 이내에 3회이상 경고 떠야 알람 울릴 것인지\n",
    "cutoff = 3 # 15분 이내에 몇개 이상일 때알람 울릴 것인지\n",
    "alarm_df = isol_score2.copy()\n",
    "alarm_df['ALARM'] = False\n",
    "for i in np.where(alarm_df['SCORE'] > threshold)[0]:\n",
    "    tmp = alarm_df[(alarm_df['MEASR_DTTM']<alarm_df.iloc[i,0])&(alarm_df['MEASR_DTTM']>=alarm_df.iloc[i,0]-datetime.timedelta(minutes=timedel))]\n",
    "    if len(tmp[tmp['SCORE']>threshold])>cutoff:\n",
    "        alarm_df.iloc[i, -1] = True\n",
    "\n",
    "tmp = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = alarm_df[(alarm_df['ALARM']==True)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]      \n",
    "print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "print('train set에서 false 알람: ', len(tmp3))\n",
    "start =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "if len(tmp2) >0:\n",
    "    start = tmp2.iloc[0,0]\n",
    "    print('가짜알람비율: ',len(tmp)/(len(tmp)+len(tmp2)))\n",
    "else:\n",
    "    print('알람없음.')\n",
    "sstart =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "end = alarm_df[alarm_df['STATUS']=='전조'].iloc[-1,0]\n",
    "\n",
    "print('최초알람시점 비율',(end-start)/(end-sstart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "from tensorflow.keras import backend as K\n",
    "checkpoint_path = 'best_weights.h5'\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data = train_data.iloc[:,1:-1].copy()\n",
    "data[:] = scaler.fit_transform(data[:])\n",
    "\n",
    "shape = data.shape\n",
    "x1 = Input(shape=(shape[1],))\n",
    "x = Lambda(lambda x: K.expand_dims(x,axis=2))(x1)\n",
    "x = Conv1D(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "x = Conv1DTranspose(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1DTranspose(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "x = Conv1DTranspose(filters=1, kernel_size=7, padding = 'same')(x)\n",
    "x = Flatten()(x)\n",
    "x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "model = Model(x1, x2)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "es = EarlyStopping(patience=10, mode='auto', monitor = 'val_loss')\n",
    "mc = ModelCheckpoint(checkpoint_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "\n",
    "model.fit(data, data, epochs=100000, validation_split= 0.1, callbacks=[es, mc], batch_size=128, verbose=1) \n",
    "model.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미 오토인코더학습 했고 불러오기만 원할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "# from tensorflow.keras import backend as K\n",
    "# checkpoint_path = 'best_weights.h5'\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# data = train_data.iloc[:,1:-1].copy()\n",
    "# data[:] = scaler.fit_transform(data[:])\n",
    "\n",
    "# shape = data.shape\n",
    "# x1 = Input(shape=(shape[1],))\n",
    "# x = Lambda(lambda x: K.expand_dims(x,axis=2))(x1)\n",
    "# x = Conv1D(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1D(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1DTranspose(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=1, kernel_size=7, padding = 'same')(x)\n",
    "# x = Flatten()(x)\n",
    "# x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "# model = Model(x1, x2)\n",
    "# model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df = df.copy()\n",
    "auto_df.iloc[:,1:-1] = scaler.transform(auto_df.iloc[:,1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(auto_df.iloc[:,1:-1])\n",
    "score = np.mean(np.abs(pred - auto_df.iloc[:,1:-1]), axis=1)\n",
    "\n",
    "auto_score = df[['MEASR_DTTM', 'STATUS']].copy()\n",
    "auto_score['SCORE']= score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "import numpy as np\n",
    "nboot = 100\n",
    "alpha=0.0001 # 백분위 기준 이상치가 0.1%되게 threshold 설정한다는 의미\n",
    "threshold_series = auto_score[auto_score['MEASR_DTTM']<train_test_split_point]['SCORE']\n",
    "\n",
    "bootsam = np.random.choice(threshold_series, size=len(threshold_series) * nboot, replace=True, p=None)\n",
    "bootsam.shape = (nboot, len(threshold_series))\n",
    "\n",
    "auto_threshold  = np.mean(np.percentile(bootsam, q=(1 - alpha) * 100, axis=1))\n",
    "auto_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = auto_threshold\n",
    "# threshold =0.12\n",
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "import plotly.express as px\n",
    "plot_df = auto_score.copy()\n",
    "# threshold 아래부분 sampling해서 그래프 용량 줄이기\n",
    "if len(plot_df) > 100000:\n",
    "    tmp = plot_df[plot_df['SCORE'] < threshold].sort_values(by='SCORE', ascending = False).copy()\n",
    "    tmp = tmp[:100000]\n",
    "    plot_df = pd.concat((tmp, plot_df[plot_df['SCORE']>=threshold]))\n",
    "    plot_df = plot_df.sort_values('MEASR_DTTM')\n",
    "\n",
    "plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "fig.add_vline(x=train_test_split_point2\n",
    "                  , line_dash=\"dash\"\n",
    "                 , annotation_text = 'Test 구간'\n",
    "    #               , line_color=\"red\"\n",
    "                 )\n",
    "fig.add_hrect(\n",
    "    y0=threshold, \n",
    "    y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "    annotation_text = '정상구간',\n",
    "    fillcolor=\"green\", opacity=0.2)\n",
    "fig.show()\n",
    "# test set에서 false 알람.\n",
    "tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "print('test set에서 false 경고: ', len(tmp), 'test set에서 true 경고: ', len(tmp2))\n",
    "print('train set에서 false 경고: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15분 내 3번 경고시 알람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timedel = 15 # 몇분 이내에 3회이상 경고 떠야 알람 울릴 것인지\n",
    "cutoff = 3 # 15분 이내에 몇개 이상일 때알람 울릴 것인지\n",
    "alarm_df = auto_score.copy()\n",
    "alarm_df['ALARM'] = False\n",
    "for i in np.where(alarm_df['SCORE'] > threshold)[0]:\n",
    "    tmp = alarm_df[(alarm_df['MEASR_DTTM']<alarm_df.iloc[i,0])&(alarm_df['MEASR_DTTM']>=alarm_df.iloc[i,0]-datetime.timedelta(minutes=timedel))]\n",
    "    if len(tmp[tmp['SCORE']>threshold])>cutoff:\n",
    "        alarm_df.iloc[i, -1] = True\n",
    "\n",
    "tmp = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = alarm_df[(alarm_df['ALARM']==True)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]      \n",
    "print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "print('train set에서 false 알람: ', len(tmp3))\n",
    "start =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "if len(tmp2) >0:\n",
    "    start = tmp2.iloc[0,0]\n",
    "    print('가짜알람비율: ',len(tmp)/(len(tmp)+len(tmp2)))\n",
    "else:\n",
    "    print('알람없음.')\n",
    "sstart =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "end = alarm_df[alarm_df['STATUS']=='전조'].iloc[-1,0]\n",
    "\n",
    "print('최초알람시점 비율',(end-start)/(end-sstart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y만 사용한 오토인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "from tensorflow.keras import backend as K\n",
    "checkpoint_path = 'best_weights_Y.h5'\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data2 = train_data.iloc[:,11:21].copy()\n",
    "data2[:] = scaler.fit_transform(data2[:])\n",
    "\n",
    "shape = data2.shape\n",
    "x1 = Input(shape=(shape[1],))\n",
    "x = Lambda(lambda x: K.expand_dims(x,axis=2))(x1)\n",
    "x = Conv1D(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "x = Conv1DTranspose(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1DTranspose(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "x = Conv1DTranspose(filters=1, kernel_size=7, padding = 'same')(x)\n",
    "x = Flatten()(x)\n",
    "x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "model2 = Model(x1, x2)\n",
    "\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "es = EarlyStopping(patience=10, mode='auto', monitor = 'val_loss')\n",
    "mc = ModelCheckpoint(checkpoint_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "\n",
    "model2.fit(data2, data2, epochs=100000, validation_split= 0.1, callbacks=[es, mc], batch_size=128, verbose=1) \n",
    "model2.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미 오토인코더학습 했고 불러오기만 원할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "# from tensorflow.keras import backend as K\n",
    "# checkpoint_path = 'best_weights_Y.h5'\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# data2 = train_data.iloc[:,11:21].copy()\n",
    "# data2[:] = scaler.fit_transform(data2[:])\n",
    "\n",
    "# shape = data2.shape\n",
    "# x1 = Input(shape=(shape[1],))\n",
    "# x = Lambda(lambda x: K.expand_dims(x,axis=2))(x1)\n",
    "# x = Conv1D(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1D(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1DTranspose(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=1, kernel_size=7, padding = 'same')(x)\n",
    "# x = Flatten()(x)\n",
    "# x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "# model2 = Model(x1, x2)\n",
    "# model2.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df2 = df.copy()\n",
    "auto_df2.iloc[:,11:21] = scaler.transform(auto_df.iloc[:,11:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model2.predict(auto_df2.iloc[:,11:21])\n",
    "score = np.mean(np.abs(pred - auto_df2.iloc[:,11:21]), axis=1)\n",
    "\n",
    "auto_score2 = df[['MEASR_DTTM', 'STATUS']].copy()\n",
    "auto_score2['SCORE']= score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "import numpy as np\n",
    "nboot = 100\n",
    "alpha=0.0001 # 백분위 기준 이상치가 0.1%되게 threshold 설정한다는 의미\n",
    "threshold_series = auto_score2[auto_score2['MEASR_DTTM']<train_test_split_point]['SCORE']\n",
    "\n",
    "bootsam = np.random.choice(threshold_series, size=len(threshold_series) * nboot, replace=True, p=None)\n",
    "bootsam.shape = (nboot, len(threshold_series))\n",
    "\n",
    "auto_threshold2  = np.mean(np.percentile(bootsam, q=(1 - alpha) * 100, axis=1))\n",
    "auto_threshold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = auto_threshold2\n",
    "# threshold =0.12\n",
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "import plotly.express as px\n",
    "plot_df = auto_score2.copy()\n",
    "# threshold 아래부분 sampling해서 그래프 용량 줄이기\n",
    "if len(plot_df) > 100000:\n",
    "    tmp = plot_df[plot_df['SCORE'] < threshold].sort_values(by='SCORE', ascending = False).copy()\n",
    "    tmp = tmp[:100000]\n",
    "    plot_df = pd.concat((tmp, plot_df[plot_df['SCORE']>=threshold]))\n",
    "    plot_df = plot_df.sort_values('MEASR_DTTM')\n",
    "\n",
    "plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "fig.add_vline(x=train_test_split_point2\n",
    "                  , line_dash=\"dash\"\n",
    "                 , annotation_text = 'Test 구간'\n",
    "    #               , line_color=\"red\"\n",
    "                 )\n",
    "fig.add_hrect(\n",
    "    y0=threshold, \n",
    "    y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "    annotation_text = '정상구간',\n",
    "    fillcolor=\"green\", opacity=0.2)\n",
    "fig.show()\n",
    "# test set에서 false 알람.\n",
    "tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "print('test set에서 false 경고: ', len(tmp), 'test set에서 true 경고: ', len(tmp2))\n",
    "print('train set에서 false 경고: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15분 내 3번 경고시 알람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timedel = 15 # 몇분 이내에 3회이상 경고 떠야 알람 울릴 것인지\n",
    "cutoff = 3 # 15분 이내에 몇개 이상일 때알람 울릴 것인지\n",
    "alarm_df = auto_score2.copy()\n",
    "alarm_df['ALARM'] = False\n",
    "for i in np.where(alarm_df['SCORE'] > threshold)[0]:\n",
    "    tmp = alarm_df[(alarm_df['MEASR_DTTM']<alarm_df.iloc[i,0])&(alarm_df['MEASR_DTTM']>=alarm_df.iloc[i,0]-datetime.timedelta(minutes=timedel))]\n",
    "    if len(tmp[tmp['SCORE']>threshold])>cutoff:\n",
    "        alarm_df.iloc[i, -1] = True\n",
    "\n",
    "tmp = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = alarm_df[(alarm_df['ALARM']==True)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]      \n",
    "print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "print('train set에서 false 알람: ', len(tmp3))\n",
    "start =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "if len(tmp2) >0:\n",
    "    start = tmp2.iloc[0,0]\n",
    "    print('가짜알람비율: ',len(tmp)/(len(tmp)+len(tmp2)))\n",
    "else:\n",
    "    print('알람없음.')\n",
    "sstart =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "end = alarm_df[alarm_df['STATUS']=='전조'].iloc[-1,0]\n",
    "\n",
    "print('최초알람시점 비율',(end-start)/(end-sstart))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y만 활용했을 때보다 X, Z 모두 활용했을 때 더강력해보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # threshold =0.12\n",
    "# train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "# train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "# import plotly.express as px\n",
    "# plot_df = auto_score.copy()\n",
    "\n",
    "# plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "# fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "# fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "# fig.add_vline(x=train_test_split_point2\n",
    "#                   , line_dash=\"dash\"\n",
    "#                  , annotation_text = 'Test 구간'\n",
    "#     #               , line_color=\"red\"\n",
    "#                  )\n",
    "# fig.add_hrect(\n",
    "#     y0=threshold, \n",
    "#     y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "#     annotation_text = '정상구간',\n",
    "#     fillcolor=\"green\", opacity=0.2)\n",
    "# fig.show()\n",
    "# # test set에서 false 알람.\n",
    "# tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "# tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "# tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "# tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "# tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "# tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "# print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "# print('train set에서 false 알람: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 아래 두개는 용량이 커서  시행이 안됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "if len(data) > 100000:\n",
    "    tmp =  np.random.choice(data.index, size = 100000)\n",
    "    svm_data = data.loc[tmp,:].copy()\n",
    "svm = OneClassSVM(max_iter = 10000).fit(svm_data) # auto encoder에서 사용한거 그대로 사용. / 데이터가 많아 kernel svm을 못사용함.\n",
    "\n",
    "svm_score = df[['MEASR_DTTM', 'STATUS']].copy()\n",
    "svm_score['SCORE']= svm.score_samples(auto_df.iloc[:,1:-1])*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "import numpy as np\n",
    "nboot = 100\n",
    "alpha=0.0001 # 백분위 기준 이상치가 0.1%되게 threshold 설정한다는 의미\n",
    "threshold_series = svm_score[svm_score['MEASR_DTTM']<train_test_split_point]['SCORE']\n",
    "\n",
    "bootsam = np.random.choice(threshold_series, size=len(threshold_series) * nboot, replace=True, p=None)\n",
    "bootsam.shape = (nboot, len(threshold_series))\n",
    "\n",
    "svm_threshold  = np.mean(np.percentile(bootsam, q=(1 - alpha) * 100, axis=1))\n",
    "svm_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = svm_score.copy()\n",
    "threshold = svm_threshold\n",
    "# threshold =0.12\n",
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "import plotly.express as px\n",
    "\n",
    "# threshold 아래부분 sampling해서 그래프 용량 줄이기\n",
    "if len(plot_df) > 100000:\n",
    "    tmp = plot_df[plot_df['SCORE'] < threshold].sort_values(by='SCORE', ascending = False).copy()\n",
    "    tmp = tmp[:100000]\n",
    "    plot_df = pd.concat((tmp, plot_df[plot_df['SCORE']>=threshold]))\n",
    "    plot_df = plot_df.sort_values('MEASR_DTTM')\n",
    "\n",
    "plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "fig.add_vline(x=train_test_split_point2\n",
    "                  , line_dash=\"dash\"\n",
    "                 , annotation_text = 'Test 구간'\n",
    "    #               , line_color=\"red\"\n",
    "                 )\n",
    "fig.add_hrect(\n",
    "    y0=threshold, \n",
    "    y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "    annotation_text = '정상구간',\n",
    "    fillcolor=\"green\", opacity=0.2)\n",
    "fig.show()\n",
    "# test set에서 false 알람.\n",
    "tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "print('test set에서 false 경고: ', len(tmp), 'test set에서 true 경고: ', len(tmp2))\n",
    "print('train set에서 false 경고: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전조구간에서 얼마나 빨리 울렸는지 : 최초 알람 발생 시점 (70시간 / 90시간 1에 가까울 수록 최초 알람 발생 시점이 빠른 measure)\n",
    "# 전조구간에 얼마나 많이 울렸는지, 정상구간에 얼마나 적게 울렸는지 : false alarm rate : 18 / 747\n",
    "# 전조구간에 얼마나 많이 울렸는지    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15분 내 3번 경고시 알람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timedel = 15 # 몇분 이내에 3회이상 경고 떠야 알람 울릴 것인지\n",
    "cutoff = 3 # 15분 이내에 몇개 이상일 때알람 울릴 것인지\n",
    "alarm_df = svm_score.copy()\n",
    "alarm_df['ALARM'] = False\n",
    "for i in np.where(alarm_df['SCORE'] > threshold)[0]:\n",
    "    tmp = alarm_df[(alarm_df['MEASR_DTTM']<alarm_df.iloc[i,0])&(alarm_df['MEASR_DTTM']>=alarm_df.iloc[i,0]-datetime.timedelta(minutes=timedel))]\n",
    "    if len(tmp[tmp['SCORE']>threshold])>cutoff:\n",
    "        alarm_df.iloc[i, -1] = True\n",
    "\n",
    "tmp = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = alarm_df[(alarm_df['ALARM']==True)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]   \n",
    "\n",
    "\n",
    "print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "print('train set에서 false 알람: ', len(tmp3))\n",
    "start =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "if len(tmp2) >0:\n",
    "    start = tmp2.iloc[0,0]\n",
    "    print('가짜알람비율: ',len(tmp)/(len(tmp)+len(tmp2)))\n",
    "else:\n",
    "    print('알람없음.')\n",
    "sstart =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "end = alarm_df[alarm_df['STATUS']=='전조'].iloc[-1,0]\n",
    "\n",
    "print('최초알람시점 비율',(end-start)/(end-sstart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "lof = LocalOutlierFactor(novelty=True, n_jobs=8).fit(data) # auto encoder에서 사용한거 그대로 사용.\n",
    "lof_score = df[['MEASR_DTTM', 'STATUS']].copy()\n",
    "lof_score['SCORE']= lof.score_samples(auto_df.iloc[:,1:-1])*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "import numpy as np\n",
    "nboot = 100\n",
    "alpha=0.0001 # 백분위 기준 이상치가 0.1%되게 threshold 설정한다는 의미\n",
    "threshold_series = lof_score[lof_score['MEASR_DTTM']<train_test_split_point]['SCORE']\n",
    "\n",
    "bootsam = np.random.choice(threshold_series, size=len(threshold_series) * nboot, replace=True, p=None)\n",
    "bootsam.shape = (nboot, len(threshold_series))\n",
    "\n",
    "lof_threshold  = np.mean(np.percentile(bootsam, q=(1 - alpha) * 100, axis=1))\n",
    "lof_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = lof_score.copy()\n",
    "threshold = lof_threshold\n",
    "# threshold =0.12\n",
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "import plotly.express as px\n",
    "\n",
    "# threshold 아래부분 sampling해서 그래프 용량 줄이기\n",
    "if len(plot_df) > 100000:\n",
    "    tmp = plot_df[plot_df['SCORE'] < threshold].sort_values(by='SCORE', ascending = False).copy()\n",
    "    tmp = tmp[:100000]\n",
    "    plot_df = pd.concat((tmp, plot_df[plot_df['SCORE']>=threshold]))\n",
    "    plot_df = plot_df.sort_values('MEASR_DTTM')\n",
    "\n",
    "plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "fig.add_vline(x=train_test_split_point2\n",
    "                  , line_dash=\"dash\"\n",
    "                 , annotation_text = 'Test 구간'\n",
    "    #               , line_color=\"red\"\n",
    "                 )\n",
    "fig.add_hrect(\n",
    "    y0=threshold, \n",
    "    y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "    annotation_text = '정상구간',\n",
    "    fillcolor=\"green\", opacity=0.2)\n",
    "fig.show()\n",
    "# test set에서 false 알람.\n",
    "tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "print('test set에서 false 경고: ', len(tmp), 'test set에서 true 경고: ', len(tmp2))\n",
    "print('train set에서 false 경고: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15분 내 3번 경고시 알람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timedel = 15 # 몇분 이내에 3회이상 경고 떠야 알람 울릴 것인지\n",
    "cutoff = 3 # 15분 이내에 몇개 이상일 때알람 울릴 것인지\n",
    "alarm_df = lof_score.copy()\n",
    "alarm_df['ALARM'] = False\n",
    "for i in np.where(alarm_df['SCORE'] > threshold)[0]:\n",
    "    tmp = alarm_df[(alarm_df['MEASR_DTTM']<alarm_df.iloc[i,0])&(alarm_df['MEASR_DTTM']>=alarm_df.iloc[i,0]-datetime.timedelta(minutes=timedel))]\n",
    "    if len(tmp[tmp['SCORE']>threshold])>cutoff:\n",
    "        alarm_df.iloc[i, -1] = True\n",
    "\n",
    "tmp = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = alarm_df[(alarm_df['ALARM']==True)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]      \n",
    "print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "print('train set에서 false 알람: ', len(tmp3))\n",
    "start =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "if len(tmp2) >0:\n",
    "    start = tmp2.iloc[0,0]\n",
    "    print('가짜알람비율: ',len(tmp)/(len(tmp)+len(tmp2)))\n",
    "else:\n",
    "    print('알람없음.')\n",
    "sstart =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "end = alarm_df[alarm_df['STATUS']=='전조'].iloc[-1,0]\n",
    "\n",
    "print('최초알람시점 비율',(end-start)/(end-sstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EllipticEnvelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "ellip = EllipticEnvelope(random_state=0).fit(data) # auto encoder에서 사용한거 그대로 사용.\n",
    "ellip_score = df[['MEASR_DTTM', 'STATUS']].copy()\n",
    "ellip_score['SCORE']= ellip.score_samples(auto_df.iloc[:,1:-1])*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "import numpy as np\n",
    "nboot = 100\n",
    "alpha=0.0001 # 백분위 기준 이상치가 0.1%되게 threshold 설정한다는 의미\n",
    "threshold_series = ellip_score[ellip_score['MEASR_DTTM']<train_test_split_point]['SCORE']\n",
    "\n",
    "bootsam = np.random.choice(threshold_series, size=len(threshold_series) * nboot, replace=True, p=None)\n",
    "bootsam.shape = (nboot, len(threshold_series))\n",
    "\n",
    "ellip_threshold  = np.mean(np.percentile(bootsam, q=(1 - alpha) * 100, axis=1))\n",
    "ellip_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = ellip_score.copy()\n",
    "threshold = ellip_threshold\n",
    "# threshold =0.12\n",
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "import plotly.express as px\n",
    "\n",
    "# threshold 아래부분 sampling해서 그래프 용량 줄이기\n",
    "if len(plot_df) > 100000:\n",
    "    tmp = plot_df[plot_df['SCORE'] < threshold].sort_values(by='SCORE', ascending = False).copy()\n",
    "    tmp = tmp[:100000]\n",
    "    plot_df = pd.concat((tmp, plot_df[plot_df['SCORE']>=threshold]))\n",
    "    plot_df = plot_df.sort_values('MEASR_DTTM')\n",
    "\n",
    "plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "fig.add_vline(x=train_test_split_point2\n",
    "                  , line_dash=\"dash\"\n",
    "                 , annotation_text = 'Test 구간'\n",
    "    #               , line_color=\"red\"\n",
    "                 )\n",
    "fig.add_hrect(\n",
    "    y0=threshold, \n",
    "    y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "    annotation_text = '정상구간',\n",
    "    fillcolor=\"green\", opacity=0.2)\n",
    "fig.show()\n",
    "# test set에서 false 알람.\n",
    "tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "print('test set에서 false 경고: ', len(tmp), 'test set에서 true 경고: ', len(tmp2))\n",
    "print('train set에서 false 경고: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15분 내 3번 경고시 알람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timedel = 15 # 몇분 이내에 3회이상 경고 떠야 알람 울릴 것인지\n",
    "cutoff = 3 # 15분 이내에 몇개 이상일 때알람 울릴 것인지\n",
    "alarm_df = ellip_score.copy()\n",
    "alarm_df['ALARM'] = False\n",
    "for i in np.where(alarm_df['SCORE'] > threshold)[0]:\n",
    "    tmp = alarm_df[(alarm_df['MEASR_DTTM']<alarm_df.iloc[i,0])&(alarm_df['MEASR_DTTM']>=alarm_df.iloc[i,0]-datetime.timedelta(minutes=timedel))]\n",
    "    if len(tmp[tmp['SCORE']>threshold])>cutoff:\n",
    "        alarm_df.iloc[i, -1] = True\n",
    "\n",
    "tmp = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = alarm_df[(alarm_df['ALARM']==True)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]      \n",
    "print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "print('train set에서 false 알람: ', len(tmp3))\n",
    "start =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "if len(tmp2) >0:\n",
    "    start = tmp2.iloc[0,0]\n",
    "    print('가짜알람비율: ',len(tmp)/(len(tmp)+len(tmp2)))\n",
    "else:\n",
    "    print('알람없음.')\n",
    "sstart =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "end = alarm_df[alarm_df['STATUS']=='전조'].iloc[-1,0]\n",
    "\n",
    "print('최초알람시점 비율',(end-start)/(end-sstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Encoder(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "from tensorflow.keras import backend as K\n",
    "checkpoint_path = 'best_weights2.h5'\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data = train_data.iloc[:,1:-1].copy()\n",
    "data[:] = scaler.fit_transform(data[:])\n",
    "\n",
    "shape = data.shape\n",
    "x1 = Input(shape=(shape[1],))\n",
    "x = Dense(30, activation='relu')(x1)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(30, activation='relu')(x1)\n",
    "x = Dropout(0.2)(x)\n",
    "x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "model = Model(x1, x2)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "es = EarlyStopping(patience=10, mode='auto', monitor = 'val_loss')\n",
    "mc = ModelCheckpoint(checkpoint_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "\n",
    "model.fit(data, data, epochs=100000, validation_split= 0.1, callbacks=[es, mc], batch_size=128, verbose=1) \n",
    "model.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미 오토인코더학습 했고 불러오기만 원할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "# from tensorflow.keras import backend as K\n",
    "# checkpoint_path = 'best_weights.h5'\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# data = train_data.iloc[:,1:-1].copy()\n",
    "# data[:] = scaler.fit_transform(data[:])\n",
    "\n",
    "# shape = data.shape\n",
    "# x1 = Input(shape=(shape[1],))\n",
    "# x = Lambda(lambda x: K.expand_dims(x,axis=2))(x1)\n",
    "# x = Conv1D(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1D(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1DTranspose(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=1, kernel_size=7, padding = 'same')(x)\n",
    "# x = Flatten()(x)\n",
    "# x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "# model = Model(x1, x2)\n",
    "# model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df = df.copy()\n",
    "auto_df.iloc[:,1:-1] = scaler.transform(auto_df.iloc[:,1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(auto_df.iloc[:,1:-1])\n",
    "score = np.mean(np.abs(pred - auto_df.iloc[:,1:-1]), axis=1)\n",
    "\n",
    "auto_score = df[['MEASR_DTTM', 'STATUS']].copy()\n",
    "auto_score['SCORE']= score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "import numpy as np\n",
    "nboot = 100\n",
    "alpha=0.0001 # 백분위 기준 이상치가 0.1%되게 threshold 설정한다는 의미\n",
    "threshold_series = auto_score[auto_score['MEASR_DTTM']<train_test_split_point]['SCORE']\n",
    "\n",
    "bootsam = np.random.choice(threshold_series, size=len(threshold_series) * nboot, replace=True, p=None)\n",
    "bootsam.shape = (nboot, len(threshold_series))\n",
    "\n",
    "auto_threshold  = np.mean(np.percentile(bootsam, q=(1 - alpha) * 100, axis=1))\n",
    "auto_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = auto_threshold\n",
    "# threshold =0.12\n",
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "import plotly.express as px\n",
    "plot_df = auto_score.copy()\n",
    "# threshold 아래부분 sampling해서 그래프 용량 줄이기\n",
    "if len(plot_df) > 100000:\n",
    "    tmp = plot_df[plot_df['SCORE'] < threshold].sort_values(by='SCORE', ascending = False).copy()\n",
    "    tmp = tmp[:100000]\n",
    "    plot_df = pd.concat((tmp, plot_df[plot_df['SCORE']>=threshold]))\n",
    "    plot_df = plot_df.sort_values('MEASR_DTTM')\n",
    "\n",
    "plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "fig.add_vline(x=train_test_split_point2\n",
    "                  , line_dash=\"dash\"\n",
    "                 , annotation_text = 'Test 구간'\n",
    "    #               , line_color=\"red\"\n",
    "                 )\n",
    "fig.add_hrect(\n",
    "    y0=threshold, \n",
    "    y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "    annotation_text = '정상구간',\n",
    "    fillcolor=\"green\", opacity=0.2)\n",
    "fig.show()\n",
    "# test set에서 false 알람.\n",
    "tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "print('test set에서 false 경고: ', len(tmp), 'test set에서 true 경고: ', len(tmp2))\n",
    "print('train set에서 false 경고: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15분 내 3번 경고시 알람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timedel = 15 # 몇분 이내에 3회이상 경고 떠야 알람 울릴 것인지\n",
    "cutoff = 3 # 15분 이내에 몇개 이상일 때알람 울릴 것인지\n",
    "alarm_df = auto_score.copy()\n",
    "alarm_df['ALARM'] = False\n",
    "for i in np.where(alarm_df['SCORE'] > threshold)[0]:\n",
    "    tmp = alarm_df[(alarm_df['MEASR_DTTM']<alarm_df.iloc[i,0])&(alarm_df['MEASR_DTTM']>=alarm_df.iloc[i,0]-datetime.timedelta(minutes=timedel))]\n",
    "    if len(tmp[tmp['SCORE']>threshold])>cutoff:\n",
    "        alarm_df.iloc[i, -1] = True\n",
    "\n",
    "tmp = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = alarm_df[(alarm_df['ALARM']==True)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]      \n",
    "print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "print('train set에서 false 알람: ', len(tmp3))\n",
    "start =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "if len(tmp2) >0:\n",
    "    start = tmp2.iloc[0,0]\n",
    "    print('가짜알람비율: ',len(tmp)/(len(tmp)+len(tmp2)))\n",
    "else:\n",
    "    print('알람없음.')\n",
    "sstart =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "end = alarm_df[alarm_df['STATUS']=='전조'].iloc[-1,0]\n",
    "\n",
    "print('최초알람시점 비율',(end-start)/(end-sstart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y만 사용한 오토인코더(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "from tensorflow.keras import backend as K\n",
    "checkpoint_path = 'best_weights_Y2.h5'\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data2 = train_data.iloc[:,11:21].copy()\n",
    "data2[:] = scaler.fit_transform(data2[:])\n",
    "\n",
    "shape = data2.shape\n",
    "x1 = Input(shape=(shape[1],))\n",
    "x = Dense(30, activation='relu')(x1)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(30, activation='relu')(x1)\n",
    "x = Dropout(0.2)(x)\n",
    "x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "model2 = Model(x1, x2)\n",
    "\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "es = EarlyStopping(patience=10, mode='auto', monitor = 'val_loss')\n",
    "mc = ModelCheckpoint(checkpoint_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "\n",
    "model2.fit(data2, data2, epochs=100000, validation_split= 0.1, callbacks=[es, mc], batch_size=128, verbose=1) \n",
    "model2.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미 오토인코더학습 했고 불러오기만 원할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "# from tensorflow.keras import backend as K\n",
    "# checkpoint_path = 'best_weights_Y.h5'\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# data2 = train_data.iloc[:,11:21].copy()\n",
    "# data2[:] = scaler.fit_transform(data2[:])\n",
    "\n",
    "# shape = data2.shape\n",
    "# x1 = Input(shape=(shape[1],))\n",
    "# x = Lambda(lambda x: K.expand_dims(x,axis=2))(x1)\n",
    "# x = Conv1D(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1D(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1DTranspose(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=1, kernel_size=7, padding = 'same')(x)\n",
    "# x = Flatten()(x)\n",
    "# x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "# model2 = Model(x1, x2)\n",
    "# model2.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df2 = df.copy()\n",
    "auto_df2.iloc[:,11:21] = scaler.transform(auto_df2.iloc[:,11:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model2.predict(auto_df2.iloc[:,11:21])\n",
    "score = np.mean(np.abs(pred - auto_df2.iloc[:,11:21]), axis=1)\n",
    "\n",
    "auto_score2 = df[['MEASR_DTTM', 'STATUS']].copy()\n",
    "auto_score2['SCORE']= score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "import numpy as np\n",
    "nboot = 100\n",
    "alpha=0.0001 # 백분위 기준 이상치가 0.1%되게 threshold 설정한다는 의미\n",
    "threshold_series = auto_score2[auto_score2['MEASR_DTTM']<train_test_split_point]['SCORE']\n",
    "\n",
    "bootsam = np.random.choice(threshold_series, size=len(threshold_series) * nboot, replace=True, p=None)\n",
    "bootsam.shape = (nboot, len(threshold_series))\n",
    "\n",
    "auto_threshold2  = np.mean(np.percentile(bootsam, q=(1 - alpha) * 100, axis=1))\n",
    "auto_threshold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = auto_threshold2\n",
    "# threshold =0.12\n",
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "import plotly.express as px\n",
    "plot_df = auto_score2.copy()\n",
    "# threshold 아래부분 sampling해서 그래프 용량 줄이기\n",
    "if len(plot_df) > 100000:\n",
    "    tmp = plot_df[plot_df['SCORE'] < threshold].sort_values(by='SCORE', ascending = False).copy()\n",
    "    tmp = tmp[:100000]\n",
    "    plot_df = pd.concat((tmp, plot_df[plot_df['SCORE']>=threshold]))\n",
    "    plot_df = plot_df.sort_values('MEASR_DTTM')\n",
    "\n",
    "plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "fig.add_vline(x=train_test_split_point2\n",
    "                  , line_dash=\"dash\"\n",
    "                 , annotation_text = 'Test 구간'\n",
    "    #               , line_color=\"red\"\n",
    "                 )\n",
    "fig.add_hrect(\n",
    "    y0=threshold, \n",
    "    y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "    annotation_text = '정상구간',\n",
    "    fillcolor=\"green\", opacity=0.2)\n",
    "fig.show()\n",
    "# test set에서 false 알람.\n",
    "tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "print('test set에서 false 경고: ', len(tmp), 'test set에서 true 경고: ', len(tmp2))\n",
    "print('train set에서 false 경고: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15분 내 3번 경고시 알람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timedel = 15 # 몇분 이내에 3회이상 경고 떠야 알람 울릴 것인지\n",
    "cutoff = 3 # 15분 이내에 몇개 이상일 때알람 울릴 것인지\n",
    "alarm_df = auto_score2.copy()\n",
    "alarm_df['ALARM'] = False\n",
    "for i in np.where(alarm_df['SCORE'] > threshold)[0]:\n",
    "    tmp = alarm_df[(alarm_df['MEASR_DTTM']<alarm_df.iloc[i,0])&(alarm_df['MEASR_DTTM']>=alarm_df.iloc[i,0]-datetime.timedelta(minutes=timedel))]\n",
    "    if len(tmp[tmp['SCORE']>threshold])>cutoff:\n",
    "        alarm_df.iloc[i, -1] = True\n",
    "\n",
    "tmp = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = alarm_df[(alarm_df['ALARM']==True)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]      \n",
    "print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "print('train set에서 false 알람: ', len(tmp3))\n",
    "start =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "if len(tmp2) >0:\n",
    "    start = tmp2.iloc[0,0]\n",
    "    print('가짜알람비율: ',len(tmp)/(len(tmp)+len(tmp2)))\n",
    "else:\n",
    "    print('알람없음.')\n",
    "sstart =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "end = alarm_df[alarm_df['STATUS']=='전조'].iloc[-1,0]\n",
    "\n",
    "print('최초알람시점 비율',(end-start)/(end-sstart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X만 사용한 오토인코더(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "from tensorflow.keras import backend as K\n",
    "checkpoint_path = 'best_weights_Y2.h5'\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data2 = train_data.iloc[:,1:11].copy()\n",
    "data2[:] = scaler.fit_transform(data2[:])\n",
    "\n",
    "shape = data2.shape\n",
    "x1 = Input(shape=(shape[1],))\n",
    "x = Dense(30, activation='relu')(x1)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(30, activation='relu')(x1)\n",
    "x = Dropout(0.2)(x)\n",
    "x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "model2 = Model(x1, x2)\n",
    "\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "es = EarlyStopping(patience=10, mode='auto', monitor = 'val_loss')\n",
    "mc = ModelCheckpoint(checkpoint_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "\n",
    "model2.fit(data2, data2, epochs=100000, validation_split= 0.1, callbacks=[es, mc], batch_size=128, verbose=1) \n",
    "model2.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미 오토인코더학습 했고 불러오기만 원할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "# from tensorflow.keras import backend as K\n",
    "# checkpoint_path = 'best_weights_Y.h5'\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# data2 = train_data.iloc[:,11:21].copy()\n",
    "# data2[:] = scaler.fit_transform(data2[:])\n",
    "\n",
    "# shape = data2.shape\n",
    "# x1 = Input(shape=(shape[1],))\n",
    "# x = Lambda(lambda x: K.expand_dims(x,axis=2))(x1)\n",
    "# x = Conv1D(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1D(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1DTranspose(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=1, kernel_size=7, padding = 'same')(x)\n",
    "# x = Flatten()(x)\n",
    "# x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "# model2 = Model(x1, x2)\n",
    "# model2.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df2 = df.copy()\n",
    "auto_df2.iloc[:,1:11] = scaler.transform(auto_df2.iloc[:,1:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model2.predict(auto_df2.iloc[:,1:11])\n",
    "score = np.mean(np.abs(pred - auto_df2.iloc[:,1:11]), axis=1)\n",
    "\n",
    "auto_score3 = df[['MEASR_DTTM', 'STATUS']].copy()\n",
    "auto_score3['SCORE']= score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "import numpy as np\n",
    "nboot = 100\n",
    "alpha=0.0001 # 백분위 기준 이상치가 0.1%되게 threshold 설정한다는 의미\n",
    "threshold_series = auto_score3[auto_score3['MEASR_DTTM']<train_test_split_point]['SCORE']\n",
    "\n",
    "bootsam = np.random.choice(threshold_series, size=len(threshold_series) * nboot, replace=True, p=None)\n",
    "bootsam.shape = (nboot, len(threshold_series))\n",
    "\n",
    "auto_threshold3  = np.mean(np.percentile(bootsam, q=(1 - alpha) * 100, axis=1))\n",
    "auto_threshold3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = auto_threshold3\n",
    "# threshold =0.12\n",
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "import plotly.express as px\n",
    "plot_df = auto_score3.copy()\n",
    "# threshold 아래부분 sampling해서 그래프 용량 줄이기\n",
    "if len(plot_df) > 100000:\n",
    "    tmp = plot_df[plot_df['SCORE'] < threshold].sort_values(by='SCORE', ascending = False).copy()\n",
    "    tmp = tmp[:100000]\n",
    "    plot_df = pd.concat((tmp, plot_df[plot_df['SCORE']>=threshold]))\n",
    "    plot_df = plot_df.sort_values('MEASR_DTTM')\n",
    "\n",
    "plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "fig.add_vline(x=train_test_split_point2\n",
    "                  , line_dash=\"dash\"\n",
    "                 , annotation_text = 'Test 구간'\n",
    "    #               , line_color=\"red\"\n",
    "                 )\n",
    "fig.add_hrect(\n",
    "    y0=threshold, \n",
    "    y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "    annotation_text = '정상구간',\n",
    "    fillcolor=\"green\", opacity=0.2)\n",
    "fig.show()\n",
    "# test set에서 false 알람.\n",
    "tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "print('test set에서 false 경고: ', len(tmp), 'test set에서 true 경고: ', len(tmp2))\n",
    "print('train set에서 false 경고: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15분 내 3번 경고시 알람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timedel = 15 # 몇분 이내에 3회이상 경고 떠야 알람 울릴 것인지\n",
    "cutoff = 3 # 15분 이내에 몇개 이상일 때알람 울릴 것인지\n",
    "alarm_df = auto_score3.copy()\n",
    "alarm_df['ALARM'] = False\n",
    "for i in np.where(alarm_df['SCORE'] > threshold)[0]:\n",
    "    tmp = alarm_df[(alarm_df['MEASR_DTTM']<alarm_df.iloc[i,0])&(alarm_df['MEASR_DTTM']>=alarm_df.iloc[i,0]-datetime.timedelta(minutes=timedel))]\n",
    "    if len(tmp[tmp['SCORE']>threshold])>cutoff:\n",
    "        alarm_df.iloc[i, -1] = True\n",
    "\n",
    "tmp = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = alarm_df[(alarm_df['ALARM']==True)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]      \n",
    "print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "print('train set에서 false 알람: ', len(tmp3))\n",
    "start =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "if len(tmp2) >0:\n",
    "    start = tmp2.iloc[0,0]\n",
    "    print('가짜알람비율: ',len(tmp)/(len(tmp)+len(tmp2)))\n",
    "else:\n",
    "    print('알람없음.')\n",
    "sstart =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "end = alarm_df[alarm_df['STATUS']=='전조'].iloc[-1,0]\n",
    "\n",
    "print('최초알람시점 비율',(end-start)/(end-sstart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z만 사용한 오토인코더(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "from tensorflow.keras import backend as K\n",
    "checkpoint_path = 'best_weights_Y2.h5'\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data2 = train_data.iloc[:,21:31].copy()\n",
    "data2[:] = scaler.fit_transform(data2[:])\n",
    "\n",
    "shape = data2.shape\n",
    "x1 = Input(shape=(shape[1],))\n",
    "x = Dense(30, activation='relu')(x1)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(30, activation='relu')(x1)\n",
    "x = Dropout(0.2)(x)\n",
    "x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "model2 = Model(x1, x2)\n",
    "\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "es = EarlyStopping(patience=10, mode='auto', monitor = 'val_loss')\n",
    "mc = ModelCheckpoint(checkpoint_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "\n",
    "model2.fit(data2, data2, epochs=100000, validation_split= 0.1, callbacks=[es, mc], batch_size=128, verbose=1) \n",
    "model2.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미 오토인코더학습 했고 불러오기만 원할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "# from tensorflow.keras import backend as K\n",
    "# checkpoint_path = 'best_weights_Y.h5'\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# data2 = train_data.iloc[:,11:21].copy()\n",
    "# data2[:] = scaler.fit_transform(data2[:])\n",
    "\n",
    "# shape = data2.shape\n",
    "# x1 = Input(shape=(shape[1],))\n",
    "# x = Lambda(lambda x: K.expand_dims(x,axis=2))(x1)\n",
    "# x = Conv1D(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1D(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1DTranspose(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=1, kernel_size=7, padding = 'same')(x)\n",
    "# x = Flatten()(x)\n",
    "# x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "# model2 = Model(x1, x2)\n",
    "# model2.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df2 = df.copy()\n",
    "auto_df2.iloc[:,21:31] = scaler.transform(auto_df2.iloc[:,21:31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model2.predict(auto_df2.iloc[:,21:31])\n",
    "score = np.mean(np.abs(pred - auto_df2.iloc[:,21:31]), axis=1)\n",
    "\n",
    "auto_score4 = df[['MEASR_DTTM', 'STATUS']].copy()\n",
    "auto_score4['SCORE']= score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "import numpy as np\n",
    "nboot = 100\n",
    "alpha=0.0001 # 백분위 기준 이상치가 0.1%되게 threshold 설정한다는 의미\n",
    "threshold_series = auto_score4[auto_score4['MEASR_DTTM']<train_test_split_point]['SCORE']\n",
    "\n",
    "bootsam = np.random.choice(threshold_series, size=len(threshold_series) * nboot, replace=True, p=None)\n",
    "bootsam.shape = (nboot, len(threshold_series))\n",
    "\n",
    "auto_threshold4  = np.mean(np.percentile(bootsam, q=(1 - alpha) * 100, axis=1))\n",
    "auto_threshold4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = auto_threshold4\n",
    "# threshold =0.12\n",
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "import plotly.express as px\n",
    "plot_df = auto_score4.copy()\n",
    "# threshold 아래부분 sampling해서 그래프 용량 줄이기\n",
    "if len(plot_df) > 100000:\n",
    "    tmp = plot_df[plot_df['SCORE'] < threshold].sort_values(by='SCORE', ascending = False).copy()\n",
    "    tmp = tmp[:100000]\n",
    "    plot_df = pd.concat((tmp, plot_df[plot_df['SCORE']>=threshold]))\n",
    "    plot_df = plot_df.sort_values('MEASR_DTTM')\n",
    "\n",
    "plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "fig.add_vline(x=train_test_split_point2\n",
    "                  , line_dash=\"dash\"\n",
    "                 , annotation_text = 'Test 구간'\n",
    "    #               , line_color=\"red\"\n",
    "                 )\n",
    "fig.add_hrect(\n",
    "    y0=threshold, \n",
    "    y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "    annotation_text = '정상구간',\n",
    "    fillcolor=\"green\", opacity=0.2)\n",
    "fig.show()\n",
    "# test set에서 false 알람.\n",
    "tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "print('test set에서 false 경고: ', len(tmp), 'test set에서 true 경고: ', len(tmp2))\n",
    "print('train set에서 false 경고: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15분 내 3번 경고시 알람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timedel = 15 # 몇분 이내에 3회이상 경고 떠야 알람 울릴 것인지\n",
    "cutoff = 3 # 15분 이내에 몇개 이상일 때알람 울릴 것인지\n",
    "alarm_df = auto_score4.copy()\n",
    "alarm_df['ALARM'] = False\n",
    "for i in np.where(alarm_df['SCORE'] > threshold)[0]:\n",
    "    tmp = alarm_df[(alarm_df['MEASR_DTTM']<alarm_df.iloc[i,0])&(alarm_df['MEASR_DTTM']>=alarm_df.iloc[i,0]-datetime.timedelta(minutes=timedel))]\n",
    "    if len(tmp[tmp['SCORE']>threshold])>cutoff:\n",
    "        alarm_df.iloc[i, -1] = True\n",
    "\n",
    "tmp = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = alarm_df[(alarm_df['ALARM']==True)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]      \n",
    "print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "print('train set에서 false 알람: ', len(tmp3))\n",
    "start =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "if len(tmp2) >0:\n",
    "    start = tmp2.iloc[0,0]\n",
    "    print('가짜알람비율: ',len(tmp)/(len(tmp)+len(tmp2)))\n",
    "else:\n",
    "    print('알람없음.')\n",
    "sstart =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "end = alarm_df[alarm_df['STATUS']=='전조'].iloc[-1,0]\n",
    "\n",
    "print('최초알람시점 비율',(end-start)/(end-sstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y, Z만 사용한 오토인코더(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[:,1:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "from tensorflow.keras import backend as K\n",
    "checkpoint_path = 'best_weights_Y2.h5'\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data2 = train_data.iloc[:,11:31].copy()\n",
    "data2[:] = scaler.fit_transform(data2[:])\n",
    "\n",
    "shape = data2.shape\n",
    "x1 = Input(shape=(shape[1],))\n",
    "x = Dense(30, activation='relu')(x1)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(30, activation='relu')(x1)\n",
    "x = Dropout(0.2)(x)\n",
    "x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "model2 = Model(x1, x2)\n",
    "\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "es = EarlyStopping(patience=10, mode='auto', monitor = 'val_loss')\n",
    "mc = ModelCheckpoint(checkpoint_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "\n",
    "model2.fit(data2, data2, epochs=100000, validation_split= 0.1, callbacks=[es, mc], batch_size=128, verbose=1) \n",
    "model2.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미 오토인코더학습 했고 불러오기만 원할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "# from tensorflow.keras import backend as K\n",
    "# checkpoint_path = 'best_weights_Y.h5'\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# data2 = train_data.iloc[:,11:21].copy()\n",
    "# data2[:] = scaler.fit_transform(data2[:])\n",
    "\n",
    "# shape = data2.shape\n",
    "# x1 = Input(shape=(shape[1],))\n",
    "# x = Lambda(lambda x: K.expand_dims(x,axis=2))(x1)\n",
    "# x = Conv1D(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1D(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1DTranspose(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=1, kernel_size=7, padding = 'same')(x)\n",
    "# x = Flatten()(x)\n",
    "# x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "# model2 = Model(x1, x2)\n",
    "# model2.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df2 = df.copy()\n",
    "auto_df2.iloc[:,11:31] = scaler.transform(auto_df2.iloc[:,11:31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model2.predict(auto_df2.iloc[:,11:31])\n",
    "score = np.mean(np.abs(pred - auto_df2.iloc[:,11:31]), axis=1)\n",
    "\n",
    "auto_score4 = df[['MEASR_DTTM', 'STATUS']].copy()\n",
    "auto_score4['SCORE']= score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "import numpy as np\n",
    "nboot = 100\n",
    "alpha=0.0001 # 백분위 기준 이상치가 0.1%되게 threshold 설정한다는 의미\n",
    "threshold_series = auto_score4[auto_score4['MEASR_DTTM']<train_test_split_point]['SCORE']\n",
    "\n",
    "bootsam = np.random.choice(threshold_series, size=len(threshold_series) * nboot, replace=True, p=None)\n",
    "bootsam.shape = (nboot, len(threshold_series))\n",
    "\n",
    "auto_threshold4  = np.mean(np.percentile(bootsam, q=(1 - alpha) * 100, axis=1))\n",
    "auto_threshold4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = auto_threshold4\n",
    "# threshold =0.12\n",
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "import plotly.express as px\n",
    "plot_df = auto_score4.copy()\n",
    "# threshold 아래부분 sampling해서 그래프 용량 줄이기\n",
    "if len(plot_df) > 100000:\n",
    "    tmp = plot_df[plot_df['SCORE'] < threshold].sort_values(by='SCORE', ascending = False).copy()\n",
    "    tmp = tmp[:100000]\n",
    "    plot_df = pd.concat((tmp, plot_df[plot_df['SCORE']>=threshold]))\n",
    "    plot_df = plot_df.sort_values('MEASR_DTTM')\n",
    "\n",
    "plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "fig.add_vline(x=train_test_split_point2\n",
    "                  , line_dash=\"dash\"\n",
    "                 , annotation_text = 'Test 구간'\n",
    "    #               , line_color=\"red\"\n",
    "                 )\n",
    "fig.add_hrect(\n",
    "    y0=threshold, \n",
    "    y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "    annotation_text = '정상구간',\n",
    "    fillcolor=\"green\", opacity=0.2)\n",
    "fig.show()\n",
    "# test set에서 false 알람.\n",
    "tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "print('test set에서 false 경고: ', len(tmp), 'test set에서 true 경고: ', len(tmp2))\n",
    "print('train set에서 false 경고: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15분 내 3번 경고시 알람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timedel = 15 # 몇분 이내에 3회이상 경고 떠야 알람 울릴 것인지\n",
    "cutoff = 3 # 15분 이내에 몇개 이상일 때알람 울릴 것인지\n",
    "alarm_df = auto_score4.copy()\n",
    "alarm_df['ALARM'] = False\n",
    "for i in np.where(alarm_df['SCORE'] > threshold)[0]:\n",
    "    tmp = alarm_df[(alarm_df['MEASR_DTTM']<alarm_df.iloc[i,0])&(alarm_df['MEASR_DTTM']>=alarm_df.iloc[i,0]-datetime.timedelta(minutes=timedel))]\n",
    "    if len(tmp[tmp['SCORE']>threshold])>cutoff:\n",
    "        alarm_df.iloc[i, -1] = True\n",
    "\n",
    "tmp = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = alarm_df[(alarm_df['ALARM']==True)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]      \n",
    "print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "print('train set에서 false 알람: ', len(tmp3))\n",
    "start =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "if len(tmp2) >0:\n",
    "    start = tmp2.iloc[0,0]\n",
    "    print('가짜알람비율: ',len(tmp)/(len(tmp)+len(tmp2)))\n",
    "else:\n",
    "    print('알람없음.')\n",
    "sstart =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "end = alarm_df[alarm_df['STATUS']=='전조'].iloc[-1,0]\n",
    "\n",
    "print('최초알람시점 비율',(end-start)/(end-sstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y, Z만 사용한 오토인코더(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[:,1:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "from tensorflow.keras import backend as K\n",
    "checkpoint_path = 'best_weights_Y2.h5'\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data2 = train_data.iloc[:,1:31].copy()\n",
    "data2[:] = scaler.fit_transform(data2[:])\n",
    "\n",
    "shape = data2.shape\n",
    "x1 = Input(shape=(shape[1],))\n",
    "x = Dense(30, activation='relu')(x1)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(30, activation='relu')(x1)\n",
    "x = Dropout(0.2)(x)\n",
    "x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "model2 = Model(x1, x2)\n",
    "\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "es = EarlyStopping(patience=10, mode='auto', monitor = 'val_loss')\n",
    "mc = ModelCheckpoint(checkpoint_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "\n",
    "model2.fit(data2, data2, epochs=100000, validation_split= 0.1, callbacks=[es, mc], batch_size=128, verbose=1) \n",
    "model2.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미 오토인코더학습 했고 불러오기만 원할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, Dropout, Conv1D, Input, Conv1DTranspose, Lambda, Flatten\n",
    "# from tensorflow.keras import backend as K\n",
    "# checkpoint_path = 'best_weights_Y.h5'\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# data2 = train_data.iloc[:,11:21].copy()\n",
    "# data2[:] = scaler.fit_transform(data2[:])\n",
    "\n",
    "# shape = data2.shape\n",
    "# x1 = Input(shape=(shape[1],))\n",
    "# x = Lambda(lambda x: K.expand_dims(x,axis=2))(x1)\n",
    "# x = Conv1D(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1D(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=16, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Conv1DTranspose(filters=32, kernel_size=7, padding = 'same', strides=2, activation='relu')(x)\n",
    "# x = Conv1DTranspose(filters=1, kernel_size=7, padding = 'same')(x)\n",
    "# x = Flatten()(x)\n",
    "# x2 = Dense(shape[1], activation='sigmoid')(x)\n",
    "\n",
    "# model2 = Model(x1, x2)\n",
    "# model2.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df2 = df.copy()\n",
    "auto_df2.iloc[:,1:31] = scaler.transform(auto_df2.iloc[:,1:31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model2.predict(auto_df2.iloc[:,1:31])\n",
    "score = np.mean(np.abs(pred - auto_df2.iloc[:,1:31]), axis=1)\n",
    "\n",
    "auto_score4 = df[['MEASR_DTTM', 'STATUS']].copy()\n",
    "auto_score4['SCORE']= score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "import numpy as np\n",
    "nboot = 100\n",
    "alpha=0.0001 # 백분위 기준 이상치가 0.1%되게 threshold 설정한다는 의미\n",
    "threshold_series = auto_score4[auto_score4['MEASR_DTTM']<train_test_split_point]['SCORE']\n",
    "\n",
    "bootsam = np.random.choice(threshold_series, size=len(threshold_series) * nboot, replace=True, p=None)\n",
    "bootsam.shape = (nboot, len(threshold_series))\n",
    "\n",
    "auto_threshold4  = np.mean(np.percentile(bootsam, q=(1 - alpha) * 100, axis=1))\n",
    "auto_threshold4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = auto_threshold4\n",
    "# threshold =0.12\n",
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "import plotly.express as px\n",
    "plot_df = auto_score4.copy()\n",
    "# threshold 아래부분 sampling해서 그래프 용량 줄이기\n",
    "if len(plot_df) > 100000:\n",
    "    tmp = plot_df[plot_df['SCORE'] < threshold].sort_values(by='SCORE', ascending = False).copy()\n",
    "    tmp = tmp[:100000]\n",
    "    plot_df = pd.concat((tmp, plot_df[plot_df['SCORE']>=threshold]))\n",
    "    plot_df = plot_df.sort_values('MEASR_DTTM')\n",
    "\n",
    "plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "fig.add_vline(x=train_test_split_point2\n",
    "                  , line_dash=\"dash\"\n",
    "                 , annotation_text = 'Test 구간'\n",
    "    #               , line_color=\"red\"\n",
    "                 )\n",
    "fig.add_hrect(\n",
    "    y0=threshold, \n",
    "    y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "    annotation_text = '정상구간',\n",
    "    fillcolor=\"green\", opacity=0.2)\n",
    "fig.show()\n",
    "# test set에서 false 알람.\n",
    "tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "print('test set에서 false 경고: ', len(tmp), 'test set에서 true 경고: ', len(tmp2))\n",
    "print('train set에서 false 경고: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15분 내 3번 경고시 알람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timedel = 15 # 몇분 이내에 3회이상 경고 떠야 알람 울릴 것인지\n",
    "cutoff = 3 # 15분 이내에 몇개 이상일 때알람 울릴 것인지\n",
    "alarm_df = auto_score4.copy()\n",
    "alarm_df['ALARM'] = False\n",
    "for i in np.where(alarm_df['SCORE'] > threshold)[0]:\n",
    "    tmp = alarm_df[(alarm_df['MEASR_DTTM']<alarm_df.iloc[i,0])&(alarm_df['MEASR_DTTM']>=alarm_df.iloc[i,0]-datetime.timedelta(minutes=timedel))]\n",
    "    if len(tmp[tmp['SCORE']>threshold])>cutoff:\n",
    "        alarm_df.iloc[i, -1] = True\n",
    "\n",
    "tmp = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = alarm_df[(alarm_df['ALARM']==True)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]      \n",
    "print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "print('train set에서 false 알람: ', len(tmp3))\n",
    "start =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "if len(tmp2) >0:\n",
    "    start = tmp2.iloc[0,0]\n",
    "    print('가짜알람비율: ',len(tmp)/(len(tmp)+len(tmp2)))\n",
    "else:\n",
    "    print('알람없음.')\n",
    "sstart =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "end = alarm_df[alarm_df['STATUS']=='전조'].iloc[-1,0]\n",
    "\n",
    "print('최초알람시점 비율',(end-start)/(end-sstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IsolationForest (minmax scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "isol3 = IsolationForest(random_state=0).fit(data) # auto encoder에서 사용한거 그대로 사용.\n",
    "isol3_score = df[['MEASR_DTTM', 'STATUS']].copy()\n",
    "isol3_score['SCORE']= isol3.score_samples(auto_df.iloc[:,1:-1])*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "import numpy as np\n",
    "nboot = 100\n",
    "alpha=0.0001 # 백분위 기준 이상치가 0.1%되게 threshold 설정한다는 의미\n",
    "threshold_series = isol3_score['SCORE']\n",
    "\n",
    "bootsam = np.random.choice(threshold_series, size=len(threshold_series) * nboot, replace=True, p=None)\n",
    "bootsam.shape = (nboot, len(threshold_series))\n",
    "\n",
    "isol3_threshold  = np.mean(np.percentile(bootsam, q=(1 - alpha) * 100, axis=1))\n",
    "isol3_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = isol3_score.copy()\n",
    "threshold = isol3_threshold\n",
    "# threshold =0.12\n",
    "train_test_split_point = pd.to_datetime('2021-08-27 00:00:00')\n",
    "train_test_split_point2 = train_test_split_point.timestamp()*1000\n",
    "import plotly.express as px\n",
    "\n",
    "# threshold 아래부분 sampling해서 그래프 용량 줄이기\n",
    "if len(plot_df) > 100000:\n",
    "    tmp = plot_df[plot_df['SCORE'] < threshold].sort_values(by='SCORE', ascending = False).copy()\n",
    "    tmp = tmp[:100000]\n",
    "    plot_df = pd.concat((tmp, plot_df[plot_df['SCORE']>=threshold]))\n",
    "    plot_df = plot_df.sort_values('MEASR_DTTM')\n",
    "\n",
    "plot_df.rename(columns={'SCORE': '이상 점수'}, inplace = True)  \n",
    "fig = px.scatter(plot_df, x='MEASR_DTTM', y='이상 점수', color='STATUS')\n",
    "fig.add_hline(y=threshold, line_dash=\"dash\", line_color = 'red', annotation_text = 'Threshold')\n",
    "fig.add_vline(x=train_test_split_point2\n",
    "                  , line_dash=\"dash\"\n",
    "                 , annotation_text = 'Test 구간'\n",
    "    #               , line_color=\"red\"\n",
    "                 )\n",
    "fig.add_hrect(\n",
    "    y0=threshold, \n",
    "    y1=np.min(plot_df['이상 점수']), line_width=0, \n",
    "    annotation_text = '정상구간',\n",
    "    fillcolor=\"green\", opacity=0.2)\n",
    "fig.show()\n",
    "# test set에서 false 알람.\n",
    "tmp = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = plot_df[(plot_df['이상 점수']>threshold)&(plot_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = plot_df[(plot_df['이상 점수']>threshold)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]\n",
    "print('test set에서 false 경고: ', len(tmp), 'test set에서 true 경고: ', len(tmp2))\n",
    "print('train set에서 false 경고: ', len(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15분 내 3번 경고시 알람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timedel = 15 # 몇분 이내에 3회이상 경고 떠야 알람 울릴 것인지\n",
    "cutoff = 3 # 15분 이내에 몇개 이상일 때알람 울릴 것인지\n",
    "alarm_df = isol3_score.copy()\n",
    "alarm_df['ALARM'] = False\n",
    "for i in np.where(alarm_df['SCORE'] > threshold)[0]:\n",
    "    tmp = alarm_df[(alarm_df['MEASR_DTTM']<alarm_df.iloc[i,0])&(alarm_df['MEASR_DTTM']>=alarm_df.iloc[i,0]-datetime.timedelta(minutes=timedel))]\n",
    "    if len(tmp[tmp['SCORE']>threshold])>cutoff:\n",
    "        alarm_df.iloc[i, -1] = True\n",
    "\n",
    "tmp = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='정상')]\n",
    "tmp = tmp[tmp['MEASR_DTTM']>train_test_split_point]\n",
    "tmp2 = alarm_df[(alarm_df['ALARM']==True)&(alarm_df['STATUS']=='전조')]\n",
    "tmp2 = tmp2[tmp2['MEASR_DTTM']>train_test_split_point]\n",
    "tmp3 = alarm_df[(alarm_df['ALARM']==True)]\n",
    "tmp3 = tmp3[tmp3['MEASR_DTTM']<train_test_split_point]      \n",
    "print('test set에서 false 알람: ', len(tmp), 'test set에서 true 알람: ', len(tmp2))\n",
    "print('train set에서 false 알람: ', len(tmp3))\n",
    "start =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "if len(tmp2) >0:\n",
    "    start = tmp2.iloc[0,0]\n",
    "    print('가짜알람비율: ',len(tmp)/(len(tmp)+len(tmp2)))\n",
    "else:\n",
    "    print('알람없음.')\n",
    "sstart =alarm_df[alarm_df['STATUS']=='전조'].iloc[0,0]\n",
    "end = alarm_df[alarm_df['STATUS']=='전조'].iloc[-1,0]\n",
    "\n",
    "print('최초알람시점 비율',(end-start)/(end-sstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
