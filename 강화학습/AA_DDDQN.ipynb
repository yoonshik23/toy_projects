{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "n_memory = 1000000\n",
    "explor = False\n",
    "fit_count = 0\n",
    "best_advanced_step=0\n",
    "bestofbest_step = 0\n",
    "exploration_rate =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out10.csv\n",
      "1 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out11.csv\n",
      "2 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out12.csv\n",
      "3 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out13.csv\n",
      "4 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out14.csv\n",
      "5 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out15.csv\n",
      "6 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out16.csv\n",
      "7 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out17.csv\n",
      "8 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out18.csv\n",
      "9 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out19.csv\n",
      "10 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out2.csv\n",
      "11 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out20.csv\n",
      "12 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out21.csv\n",
      "13 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out22.csv\n",
      "14 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out23.csv\n",
      "15 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out24.csv\n",
      "16 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out25.csv\n",
      "17 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out26.csv\n",
      "18 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out27.csv\n",
      "19 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out28.csv\n",
      "20 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out29.csv\n",
      "21 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out3.csv\n",
      "22 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out30.csv\n",
      "23 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out31.csv\n",
      "24 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out32.csv\n",
      "25 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out34.csv\n",
      "26 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out35.csv\n",
      "27 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out36.csv\n",
      "28 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out37.csv\n",
      "29 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out38.csv\n",
      "30 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out39.csv\n",
      "31 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out4.csv\n",
      "32 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out40.csv\n",
      "33 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out41.csv\n",
      "34 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out42.csv\n",
      "35 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out43.csv\n",
      "36 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out5.csv\n",
      "37 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out50.csv\n",
      "38 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out51.csv\n",
      "39 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out52.csv\n",
      "40 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out53.csv\n",
      "41 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out54.csv\n",
      "42 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out55.csv\n",
      "43 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out56.csv\n",
      "44 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out6.csv\n",
      "45 인풋데이터\\Input_Data_ID0_Step1_Value_3\\out9.csv\n"
     ]
    }
   ],
   "source": [
    "temp = r'input_data\\*csv'\n",
    "csv_dir = glob.glob(temp)\n",
    "for i in range(len(csv_dir)):\n",
    "    print(i, csv_dir[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list = []\n",
    "# for i in range(len(csv_dir)):\n",
    "#     data = pd.read_csv(csv_dir[i], header = None)\n",
    "#     tmp = data.iloc[:,0].unique()\n",
    "#     for j in range(len(tmp)):\n",
    "#         temp = data[data[0]==tmp[j]].set_index(1)\n",
    "#         temp.columns = ['prod_name', 'z_axis', 'CentSFR 0.7']\n",
    "#         df_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('df_list.pickle', 'wb') as f:\n",
    "#     pickle.dump(df_list, f)\n",
    "with open('df_list.pickle', 'rb') as f:\n",
    "    df_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prod_name</th>\n",
       "      <th>z_axis</th>\n",
       "      <th>CentSFR 0.7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20223M133784</td>\n",
       "      <td>-10.350</td>\n",
       "      <td>0.105402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20223M133784</td>\n",
       "      <td>-10.375</td>\n",
       "      <td>0.112794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20223M133784</td>\n",
       "      <td>-10.400</td>\n",
       "      <td>0.238004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20223M133784</td>\n",
       "      <td>-10.410</td>\n",
       "      <td>0.374730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20223M133784</td>\n",
       "      <td>-10.420</td>\n",
       "      <td>0.517354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20223M133784</td>\n",
       "      <td>-10.430</td>\n",
       "      <td>0.654284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20223M133784</td>\n",
       "      <td>-10.440</td>\n",
       "      <td>0.766055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20223M133784</td>\n",
       "      <td>-10.450</td>\n",
       "      <td>0.833290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20223M133784</td>\n",
       "      <td>-10.460</td>\n",
       "      <td>0.845576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20223M133784</td>\n",
       "      <td>-10.470</td>\n",
       "      <td>0.808629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20223M133784</td>\n",
       "      <td>-10.480</td>\n",
       "      <td>0.716949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        prod_name  z_axis  CentSFR 0.7\n",
       "1                                     \n",
       "0    20223M133784 -10.350     0.105402\n",
       "1    20223M133784 -10.375     0.112794\n",
       "2    20223M133784 -10.400     0.238004\n",
       "3    20223M133784 -10.410     0.374730\n",
       "4    20223M133784 -10.420     0.517354\n",
       "5    20223M133784 -10.430     0.654284\n",
       "6    20223M133784 -10.440     0.766055\n",
       "7    20223M133784 -10.450     0.833290\n",
       "8    20223M133784 -10.460     0.845576\n",
       "9    20223M133784 -10.470     0.808629\n",
       "10   20223M133784 -10.480     0.716949"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52962"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = 0.7\n",
    "idx = np.arange(0,len(df_list))\n",
    "random.shuffle(idx)\n",
    "train_df_list=[]\n",
    "test_df_list=[]\n",
    "for i in range(int(len(df_list)*train_test_ratio)):\n",
    "    train_df_list.append(df_list[idx[i]])\n",
    "for i in range(int(len(df_list)*train_test_ratio),len(df_list)):\n",
    "    test_df_list.append(df_list[idx[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide(model, cur_state):\n",
    "    global explor\n",
    "    if random.random()>exploration_rate:\n",
    "        tmp = model.predict(cur_state)\n",
    "        action = tmp.argmax()+1\n",
    "        explor = False\n",
    "    else:\n",
    "        action = random.randint(1,5)\n",
    "        explor = True\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_decide(model, cur_state):\n",
    "\n",
    "\n",
    "    tmp = model.predict(cur_state)\n",
    "    action = tmp.argmax()+1\n",
    "    explor = False\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_load(df_list):\n",
    "    i=1\n",
    "    while i!=0:\n",
    "        tmp = df_list[random.randint(0,len(df_list)-1)]\n",
    "        i = tmp.index[0]\n",
    "#     tmp = tmp.loc[tmp.fillna(0)['CentSFR 0.7']!=0,:].iloc[:-3,:]\n",
    "\n",
    "#     if len(tmp)>9:\n",
    "#         step = tmp.iloc[2:,2].argmax()+2\n",
    "    if tmp['CentSFR 0.7'].argmax() == 0:\n",
    "        step = tmp.iloc[2:,2].argmax()+2\n",
    "    else:\n",
    "        step = tmp['CentSFR 0.7'].argmax()\n",
    "    \n",
    "    value = tmp.iloc[step,:]['CentSFR 0.7']\n",
    "    return [tmp, step, value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_load(df_list,k):\n",
    "    i=1\n",
    "    while i!=0:\n",
    "        tmp = df_list[k]\n",
    "        i = tmp.index[0]\n",
    "#     tmp = tmp.loc[tmp.fillna(0)['CentSFR 0.7']!=0,:].iloc[:-3,:]\n",
    "#     if len(tmp)>9:\n",
    "#         step = tmp.iloc[2:,2].argmax()+2\n",
    "    if tmp['CentSFR 0.7'].argmax() == 0:\n",
    "        step = tmp.iloc[2:,2].argmax()+2\n",
    "    else:\n",
    "        step = tmp['CentSFR 0.7'].argmax()\n",
    "    \n",
    "    value = tmp.iloc[step,:]['CentSFR 0.7']\n",
    "    return [tmp, step, value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_env(data):\n",
    "    return [0, data[0].iloc[0,2], data[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_state: [[현재 z 거리, 바로 전 z 거리, 현재 SFR, 바로 전 SFR, 기울기]]\n",
    "def update_env(data,cur_env,action,memory_D, cur_state):\n",
    "    global terminal, fit_count, succeeded, failed\n",
    "    tmp=[]\n",
    "    tmp.append(cur_state.copy())\n",
    "    tmp.append(action)\n",
    "    \n",
    "    cur_env[0] += action # 누적 스탭\n",
    "    if cur_env[0] >= len(cur_data[0].index):\n",
    "        cur_env[1] = data[0].iloc[len(cur_data[0].index)-1,2].copy()\n",
    "    else:\n",
    "        cur_env[1] = data[0].iloc[cur_env[0],2].copy() # 현재 SFR값\n",
    "    cur_state[0][1] = cur_state[0][0].copy() # 바로 전 z 거리\n",
    "    cur_state[0][3] = cur_state[0][2].copy() # 바로 전 SFR 값\n",
    "    if cur_env[0] >= len(cur_data[0].index):\n",
    "        cur_state[0][0] = data[0].iloc[len(cur_data[0].index)-1,1].copy()\n",
    "    else:\n",
    "        cur_state[0][0] = data[0].iloc[cur_env[0],1].copy() # 현재 z 거리\n",
    "    cur_state[0][2] = cur_env[1].copy() # 현재 SFR 값\n",
    "    cur_state[0][4] = (cur_state[0][2]-cur_state[0][3])/(cur_state[0][1] - cur_state[0][0]) # 기울기 (reward)\n",
    "    \n",
    "    reward = 0\n",
    "    if cur_env[0] > cur_env[2]:\n",
    "        terminal = True\n",
    "        reward = -1\n",
    "#         print('failed')\n",
    "#         print('exploration : ', explor)\n",
    "        if explor ==False:\n",
    "            failed += 1\n",
    "    if cur_env[0] == cur_env[2]:\n",
    "        terminal = True\n",
    "        reward = 1\n",
    "#         print('succeeded')\n",
    "        succeeded += 1\n",
    "    if cur_env[0] < cur_env[2]:\n",
    "        reward = cur_state[0][2]-cur_state[0][3]\n",
    "    tmp.append(reward)\n",
    "    tmp.append(cur_state.copy())\n",
    "    tmp.append(terminal)\n",
    "    \n",
    "    memory_D.append(tmp)\n",
    "    if len(memory_D)>n_memory:\n",
    "        memory_D.pop(0)\n",
    "    fit_count += 1\n",
    "        \n",
    "    return cur_env, cur_state, reward, memory_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(model, model2, memory_D):\n",
    "    if len(memory_D)>100:\n",
    "        train_x=[]\n",
    "        delt = []\n",
    "        train_y=[]\n",
    "        for i in range(30):\n",
    "            temp = memory_D[random.randint(0,len(memory_D)-1)]\n",
    "            tmp = np.zeros(5)\n",
    "            tmp[temp[1]-1]=1.0\n",
    "\n",
    "            if temp[4] == False:\n",
    "                fu_reward = gamma*model2.predict(temp[3]).max()\n",
    "                delt.append(temp[2]+fu_reward)\n",
    "            elif temp[4] == True:\n",
    "\n",
    "                delt.append(temp[2])\n",
    "            train_x.append(copy.deepcopy(temp[0][0]))\n",
    "            train_y.append(copy.deepcopy(tmp))\n",
    "        train_y = np.asarray(train_y)\n",
    "        train_x = [np.asarray(train_x),np.asarray(delt), train_y]\n",
    "        \n",
    "        train_model.fit(train_x, train_y,verbose=0)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_fit(model, model2, memory_D):\n",
    "#     if len(memory_D)>100:\n",
    "#         train_x=[]\n",
    "#         delt = []\n",
    "#         train_y=[]\n",
    "#         for i in range(30):\n",
    "#             temp = memory_D[random.randint(0,len(memory_D)-1)]\n",
    "#             tmp = model.predict(temp[0])\n",
    "#             if temp[4] == False:\n",
    "#                 fu_reward = gamma*model2.predict(temp[3]).max()\n",
    "#                 tmp[0][temp[1]-1] = temp[2]+fu_reward\n",
    "#             elif temp[4] == True:\n",
    "\n",
    "#                 tmp[0][temp[1]-1] = temp[2]\n",
    "#             train_x.append(copy.deepcopy(temp[0][0]))\n",
    "#             train_y.append(copy.deepcopy(tmp[0]))\n",
    "#         train_x = np.asarray(train_x)\n",
    "#         train_y = np.asarray(train_y)\n",
    "        \n",
    "#         model.fit(train_x, train_y,verbose=0)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 500)          3000        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 200)          100200      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          20100       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 5)            505         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            101         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 5)            0           dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 123,906\n",
      "Trainable params: 123,906\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Input, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "def make_model():\n",
    "    def custom_loss(y_true, y_pred, delta):\n",
    "        out =  tf.math.square(tf.math.multiply(tf.math.subtract(y_pred, delta), y_true))\n",
    "        return tf.math.reduce_mean(tf.math.reduce_sum(out, axis=1))\n",
    "    delta = Input(shape=(1,),dtype= np.float32)\n",
    "    y_true = Input(shape=(5,))\n",
    "    x1 = Input(shape=(5,),dtype= np.float32)\n",
    "    x = Dense(500,activation='relu')(x1)\n",
    "    x = Dense(200,activation='relu')(x)\n",
    "    x = Dense(100,activation='relu')(x)\n",
    "    #     fc1 = Dense(50)(x)\n",
    "    advantage = Dense(5,activation='linear')(x)\n",
    "    #     fc2 = Dense(50)(x)\n",
    "    value = Dense(1)(x)\n",
    "    policy = Lambda(lambda x: tf.math.add(tf.math.subtract(x[0],tf.math.reduce_mean(x[0], 1, keepdims=True)),x[1]))([advantage, value])\n",
    "    model = Model([x1],[policy])\n",
    "    model.compile(optimizer = 'rmsprop', loss='mse')\n",
    "    train_model = Model([x1, delta, y_true],[policy])\n",
    "    train_model.add_loss(custom_loss(y_true, policy, delta))\n",
    "    train_model.compile(optimizer = Adam(learning_rate=0.00005), loss=None)\n",
    "    return model, train_model\n",
    "model, train_model = make_model()\n",
    "model2, train_model2 = make_model()\n",
    "\n",
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [np.array([[1,1,1,1,1],[1,1,1,1,1]]),np.array([[1],[1]])]\n",
    "train_y = [np.array([[0,0,0,1.0,0],[0,1.0,0,0,0]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 2.0034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.23689121, 0.63764954, 0.5936514 , 0.74322355, 0.51885885],\n",
       "       [0.23689121, 0.63764954, 0.5936514 , 0.74322355, 0.51885885]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = [np.array([[1,1,1,1,1],[1,1,1,1,1]]),np.array([[1],[1]])]\n",
    "train_y = [np.array([[0,0,0,1,0],[0,1,0,0,0]])]\n",
    "# train_model.fit(train_x,train_y,verbose=1)\n",
    "model.predict([np.array([[1,1,1,1,1],[1,1,1,1,1]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model2 updated 2622\n",
      "0.0  /  0\n",
      "2623 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.9\n",
      "명령을 따랐는데 실패한 횟수 :  106\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  0.0495002\n",
      "best model saved\n",
      "\n",
      "model2 updated 5441\n",
      "0.02  /  0.0\n",
      "2819 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.1\n",
      "명령을 따랐는데 실패한 횟수 :  17\n",
      "평균 Reward :  0.44\n",
      "exploration rate :  0.049000150000000006\n",
      "best model saved\n",
      "\n",
      "model2 updated 8170\n",
      "0.03  /  0.02\n",
      "2729 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.04\n",
      "명령을 따랐는데 실패한 횟수 :  12\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  0.048500100000000004\n",
      "best model saved\n",
      "\n",
      "model2 updated 10909\n",
      "0.07  /  0.03\n",
      "2739 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.16\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  0.048000100000000004\n",
      "best model saved\n",
      "\n",
      "model2 updated 13734\n",
      "0.02  /  0.07\n",
      "2825 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.29\n",
      "명령을 따랐는데 실패한 횟수 :  19\n",
      "평균 Reward :  0.45\n",
      "exploration rate :  0.0475001\n",
      "\n",
      "model2 updated 16696\n",
      "0.03  /  0.07\n",
      "2962 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.35\n",
      "명령을 따랐는데 실패한 횟수 :  15\n",
      "평균 Reward :  0.47\n",
      "exploration rate :  0.04700005\n",
      "\n",
      "model2 updated 19297\n",
      "0.03  /  0.07\n",
      "2601 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.86\n",
      "명령을 따랐는데 실패한 횟수 :  11\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  0.0465001\n",
      "\n",
      "model2 updated 22150\n",
      "0.05  /  0.07\n",
      "2853 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.31\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  0.046000200000000005\n",
      "\n",
      "model2 updated 24910\n",
      "0.04  /  0.07\n",
      "2760 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.1\n",
      "명령을 따랐는데 실패한 횟수 :  9\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  0.04550015\n",
      "\n",
      "model2 updated 27862\n",
      "0.02  /  0.07\n",
      "2952 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.32\n",
      "명령을 따랐는데 실패한 횟수 :  22\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  0.045000200000000004\n",
      "\n",
      "model2 updated 30781\n",
      "0.05  /  0.07\n",
      "2919 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.36\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  0.0445001\n",
      "\n",
      "model2 updated 33644\n",
      "0.01  /  0.07\n",
      "2863 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.22\n",
      "명령을 따랐는데 실패한 횟수 :  31\n",
      "평균 Reward :  0.45\n",
      "exploration rate :  0.044000250000000005\n",
      "\n",
      "model2 updated 36575\n",
      "0.02  /  0.07\n",
      "2931 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.23\n",
      "명령을 따랐는데 실패한 횟수 :  22\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  0.04350005\n",
      "\n",
      "model2 updated 39495\n",
      "0.03  /  0.07\n",
      "2920 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.32\n",
      "명령을 따랐는데 실패한 횟수 :  16\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  0.043000050000000005\n",
      "\n",
      "model2 updated 42456\n",
      "0.01  /  0.07\n",
      "2961 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.36\n",
      "명령을 따랐는데 실패한 횟수 :  44\n",
      "평균 Reward :  0.47\n",
      "exploration rate :  0.042500050000000004\n",
      "\n",
      "model2 updated 44559\n",
      "0.03  /  0.07\n",
      "2103 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.9\n",
      "명령을 따랐는데 실패한 횟수 :  12\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  0.04200045\n",
      "\n",
      "model2 updated 47115\n",
      "0.01  /  0.07\n",
      "2556 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.86\n",
      "명령을 따랐는데 실패한 횟수 :  34\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  0.04150015\n",
      "\n",
      "model2 updated 49477\n",
      "0.02  /  0.07\n",
      "2362 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.53\n",
      "명령을 따랐는데 실패한 횟수 :  24\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  0.04100005\n",
      "\n",
      "model2 updated 51847\n",
      "0.04  /  0.07\n",
      "2370 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.55\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  0.04050015\n",
      "\n",
      "model2 updated 54662\n",
      "0.03  /  0.07\n",
      "2815 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.15\n",
      "명령을 따랐는데 실패한 횟수 :  12\n",
      "평균 Reward :  0.45\n",
      "exploration rate :  0.04000015\n",
      "\n",
      "model2 updated 57552\n",
      "0.08  /  0.07\n",
      "2890 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.29\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  0.039500150000000005\n",
      "best model saved\n",
      "\n",
      "model2 updated 60217\n",
      "0.02  /  0.08\n",
      "2665 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.87\n",
      "명령을 따랐는데 실패한 횟수 :  18\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  0.039000150000000004\n",
      "\n",
      "model2 updated 62602\n",
      "0.04  /  0.08\n",
      "2385 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.54\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  0.038500150000000004\n",
      "\n",
      "model2 updated 64839\n",
      "0.02  /  0.08\n",
      "2237 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.21\n",
      "명령을 따랐는데 실패한 횟수 :  16\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  0.03800025\n",
      "\n",
      "model2 updated 67093\n",
      "0.09  /  0.08\n",
      "2254 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.34\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  0.0375002\n",
      "best model saved\n",
      "\n",
      "model2 updated 69842\n",
      "0.06  /  0.09\n",
      "2749 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.08\n",
      "명령을 따랐는데 실패한 횟수 :  7\n",
      "평균 Reward :  0.45\n",
      "exploration rate :  0.03700015\n",
      "\n",
      "model2 updated 71604\n",
      "0.02  /  0.09\n",
      "1762 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.1\n",
      "명령을 따랐는데 실패한 횟수 :  16\n",
      "평균 Reward :  0.28\n",
      "exploration rate :  0.03650015\n",
      "\n",
      "model2 updated 73584\n",
      "0.04  /  0.09\n",
      "1980 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.51\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  0.036000050000000006\n",
      "\n",
      "model2 updated 76517\n",
      "0.12  /  0.09\n",
      "2933 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.26\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.47\n",
      "exploration rate :  0.035500050000000005\n",
      "best model saved\n",
      "\n",
      "model2 updated 79184\n",
      "0.03  /  0.12\n",
      "2667 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.95\n",
      "명령을 따랐는데 실패한 횟수 :  12\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  0.035000050000000005\n",
      "\n",
      "model2 updated 81312\n",
      "0.12  /  0.12\n",
      "2128 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.04\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  0.034500050000000004\n",
      "\n",
      "model2 updated 83506\n",
      "0.04  /  0.12\n",
      "2194 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.11\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  0.034000050000000004\n",
      "\n",
      "model2 updated 85831\n",
      "0.09  /  0.12\n",
      "2325 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.34\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  0.03350005\n",
      "\n",
      "model2 updated 88288\n",
      "0.4  /  0.12\n",
      "2457 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.58\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  0.03300020000000001\n",
      "best model saved\n",
      "\n",
      "model2 updated 90509\n",
      "0.12  /  0.4\n",
      "2221 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.26\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  0.032500150000000005\n",
      "\n",
      "model2 updated 92450\n",
      "0.08  /  0.4\n",
      "1941 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.43\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  0.032000150000000005\n",
      "\n",
      "model2 updated 94253\n",
      "0.15  /  0.4\n",
      "1803 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.14\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.3\n",
      "exploration rate :  0.03150025000000001\n",
      "\n",
      "model2 updated 96082\n",
      "0.07  /  0.4\n",
      "1829 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.2\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.3\n",
      "exploration rate :  0.03100015\n",
      "\n",
      "model2 updated 97978\n",
      "0.08  /  0.4\n",
      "1896 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.41\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  0.030500200000000005\n",
      "\n",
      "model2 updated 101032\n",
      "0.03  /  0.4\n",
      "3054 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.32\n",
      "명령을 따랐는데 실패한 횟수 :  18\n",
      "평균 Reward :  0.5\n",
      "exploration rate :  0.03000005\n",
      "\n",
      "model2 updated 103074\n",
      "0.05  /  0.4\n",
      "2042 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.73\n",
      "명령을 따랐는데 실패한 횟수 :  6\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  0.029500300000000004\n",
      "\n",
      "model2 updated 104974\n",
      "0.04  /  0.4\n",
      "1900 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.34\n",
      "명령을 따랐는데 실패한 횟수 :  7\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  0.029000150000000002\n",
      "\n",
      "model2 updated 106961\n",
      "0.05  /  0.4\n",
      "1987 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.67\n",
      "명령을 따랐는데 실패한 횟수 :  6\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  0.0285001\n",
      "\n",
      "model2 updated 108926\n",
      "0.08  /  0.4\n",
      "1965 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.69\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  0.02800015\n",
      "\n",
      "model2 updated 111290\n",
      "0.02  /  0.4\n",
      "2364 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.41\n",
      "명령을 따랐는데 실패한 횟수 :  20\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  0.027500100000000003\n",
      "\n",
      "model2 updated 113715\n",
      "0.01  /  0.4\n",
      "2425 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.55\n",
      "명령을 따랐는데 실패한 횟수 :  28\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  0.0270002\n",
      "\n",
      "model2 updated 115983\n",
      "0.02  /  0.4\n",
      "2268 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.25\n",
      "명령을 따랐는데 실패한 횟수 :  15\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  0.02650005\n",
      "\n",
      "model2 updated 117965\n",
      "0.03  /  0.4\n",
      "1982 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.7\n",
      "명령을 따랐는데 실패한 횟수 :  11\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  0.026000250000000003\n",
      "\n",
      "model2 updated 120192\n",
      "0.03  /  0.4\n",
      "2227 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.15\n",
      "명령을 따랐는데 실패한 횟수 :  10\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  0.0255001\n",
      "\n",
      "model2 updated 122509\n",
      "0.05  /  0.4\n",
      "2317 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.44\n",
      "명령을 따랐는데 실패한 횟수 :  6\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  0.025000300000000003\n",
      "\n",
      "model2 updated 124840\n",
      "0.05  /  0.4\n",
      "2331 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.37\n",
      "명령을 따랐는데 실패한 횟수 :  7\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  0.0245002\n",
      "\n",
      "model2 updated 126747\n",
      "0.06  /  0.4\n",
      "1907 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.42\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  0.024000250000000004\n",
      "\n",
      "model2 updated 128662\n",
      "0.03  /  0.4\n",
      "1915 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.41\n",
      "명령을 따랐는데 실패한 횟수 :  9\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  0.02350015\n",
      "\n",
      "model2 updated 131225\n",
      "0.01  /  0.4\n",
      "2563 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.71\n",
      "명령을 따랐는데 실패한 횟수 :  33\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  0.0230002\n",
      "\n",
      "model2 updated 133445\n",
      "0.01  /  0.4\n",
      "2220 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.14\n",
      "명령을 따랐는데 실패한 횟수 :  35\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  0.022500100000000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model2 updated 135396\n",
      "0.05  /  0.4\n",
      "1951 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.52\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  0.02200015\n",
      "\n",
      "model2 updated 137698\n",
      "0.02  /  0.4\n",
      "2302 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.38\n",
      "명령을 따랐는데 실패한 횟수 :  17\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  0.021500050000000003\n",
      "\n",
      "model2 updated 140116\n",
      "0.06  /  0.4\n",
      "2418 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.44\n",
      "명령을 따랐는데 실패한 횟수 :  6\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  0.0210002\n",
      "\n",
      "model2 updated 142400\n",
      "0.03  /  0.4\n",
      "2284 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.25\n",
      "명령을 따랐는데 실패한 횟수 :  14\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  0.02050025\n",
      "\n",
      "model2 updated 145239\n",
      "0.12  /  0.4\n",
      "2839 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.1\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.47\n",
      "exploration rate :  0.0200001\n",
      "\n",
      "model2 updated 147830\n",
      "0.06  /  0.4\n",
      "2591 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.82\n",
      "명령을 따랐는데 실패한 횟수 :  6\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  0.019500100000000003\n",
      "\n",
      "model2 updated 149926\n",
      "0.07  /  0.4\n",
      "2096 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.83\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  0.01900015\n",
      "\n",
      "model2 updated 152055\n",
      "0.07  /  0.4\n",
      "2129 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.01\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  0.0185002\n",
      "\n",
      "model2 updated 153825\n",
      "0.3  /  0.4\n",
      "1770 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.97\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.3\n",
      "exploration rate :  0.018000250000000002\n",
      "\n",
      "model2 updated 155768\n",
      "0.08  /  0.4\n",
      "1943 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.6\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  0.0175002\n",
      "\n",
      "model2 updated 157852\n",
      "0.07  /  0.4\n",
      "2084 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.83\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  0.0170002\n",
      "\n",
      "model2 updated 160146\n",
      "0.39  /  0.4\n",
      "2294 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.07\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  0.016500100000000004\n",
      "\n",
      "model2 updated 162281\n",
      "0.09  /  0.4\n",
      "2135 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.01\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  0.016000100000000003\n",
      "\n",
      "model2 updated 164399\n",
      "0.09  /  0.4\n",
      "2118 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.9\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  0.015500050000000001\n",
      "\n",
      "model2 updated 166855\n",
      "0.41  /  0.4\n",
      "2456 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.51\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  0.015000100000000002\n",
      "best model saved\n",
      "\n",
      "model2 updated 168692\n",
      "0.05  /  0.41\n",
      "1837 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.28\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  0.014500250000000006\n",
      "\n",
      "model2 updated 170679\n",
      "0.04  /  0.41\n",
      "1987 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.5\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  0.014000199999999997\n",
      "\n",
      "model2 updated 172478\n",
      "0.04  /  0.41\n",
      "1799 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.97\n",
      "명령을 따랐는데 실패한 횟수 :  6\n",
      "평균 Reward :  0.3\n",
      "exploration rate :  0.013500150000000002\n",
      "\n",
      "model2 updated 174412\n",
      "0.04  /  0.41\n",
      "1934 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.49\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  0.0130003\n",
      "\n",
      "model2 updated 176337\n",
      "0.05  /  0.41\n",
      "1925 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.43\n",
      "명령을 따랐는데 실패한 횟수 :  6\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  0.0125001\n",
      "\n",
      "model2 updated 178655\n",
      "0.19  /  0.41\n",
      "2318 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.31\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  0.012000049999999998\n",
      "\n",
      "model2 updated 180807\n",
      "0.18  /  0.41\n",
      "2152 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.94\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  0.011500049999999998\n",
      "\n",
      "model2 updated 183106\n",
      "0.13  /  0.41\n",
      "2299 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.19\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  0.011000150000000007\n",
      "\n",
      "model2 updated 185832\n",
      "0.23  /  0.41\n",
      "2726 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.02\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  0.010500200000000001\n",
      "\n",
      "model2 updated 188268\n",
      "0.05  /  0.41\n",
      "2436 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.47\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  0.01000015\n",
      "\n",
      "model2 updated 190232\n",
      "0.17  /  0.41\n",
      "1964 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.48\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  0.009500100000000004\n",
      "\n",
      "model2 updated 192094\n",
      "0.16  /  0.41\n",
      "1862 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.23\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  0.009000149999999998\n",
      "\n",
      "model2 updated 193797\n",
      "0.14  /  0.41\n",
      "1703 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.8\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.29\n",
      "exploration rate :  0.008500299999999995\n",
      "\n",
      "model2 updated 195429\n",
      "0.09  /  0.41\n",
      "1632 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.42\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.28\n",
      "exploration rate :  0.008000100000000003\n",
      "\n",
      "model2 updated 197173\n",
      "0.04  /  0.41\n",
      "1744 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.89\n",
      "명령을 따랐는데 실패한 횟수 :  7\n",
      "평균 Reward :  0.29\n",
      "exploration rate :  0.007500100000000003\n",
      "\n",
      "model2 updated 198998\n",
      "0.02  /  0.41\n",
      "1825 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.03\n",
      "명령을 따랐는데 실패한 횟수 :  15\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  0.007000050000000001\n",
      "\n",
      "model2 updated 200793\n",
      "0.1  /  0.41\n",
      "1795 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.13\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.3\n",
      "exploration rate :  0.006500149999999996\n",
      "\n",
      "model2 updated 202590\n",
      "0.01  /  0.41\n",
      "1797 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.96\n",
      "명령을 따랐는데 실패한 횟수 :  21\n",
      "평균 Reward :  0.3\n",
      "exploration rate :  0.006000100000000001\n",
      "\n",
      "model2 updated 204477\n",
      "0.08  /  0.41\n",
      "1887 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.28\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  0.005500100000000001\n",
      "\n",
      "model2 updated 206837\n",
      "0.03  /  0.41\n",
      "2360 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.38\n",
      "명령을 따랐는데 실패한 횟수 :  11\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  0.0050001\n",
      "\n",
      "model2 updated 208870\n",
      "0.06  /  0.41\n",
      "2033 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.7\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  0.004500149999999994\n",
      "\n",
      "model2 updated 210736\n",
      "0.03  /  0.41\n",
      "1866 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.33\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  0.004000250000000004\n",
      "\n",
      "model2 updated 212708\n",
      "0.04  /  0.41\n",
      "1972 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.53\n",
      "명령을 따랐는데 실패한 횟수 :  7\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  0.003500099999999999\n",
      "\n",
      "model2 updated 214592\n",
      "0.32  /  0.41\n",
      "1884 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.31\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  0.00300015\n",
      "\n",
      "model2 updated 216942\n",
      "0.03  /  0.41\n",
      "2350 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.26\n",
      "명령을 따랐는데 실패한 횟수 :  11\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  0.0025001499999999996\n",
      "\n",
      "model2 updated 218989\n",
      "0.03  /  0.41\n",
      "2047 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.82\n",
      "명령을 따랐는데 실패한 횟수 :  11\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  0.002000250000000002\n",
      "\n",
      "model2 updated 220875\n",
      "0.03  /  0.41\n",
      "1886 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.38\n",
      "명령을 따랐는데 실패한 횟수 :  11\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  0.0015001499999999987\n",
      "\n",
      "model2 updated 222399\n",
      "0.09  /  0.41\n",
      "1524 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  1.98\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.26\n",
      "exploration rate :  0.0010001999999999997\n",
      "\n",
      "model2 updated 224066\n",
      "0.09  /  0.41\n",
      "1667 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.62\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.28\n",
      "exploration rate :  0.0005001499999999978\n",
      "\n",
      "model2 updated 225710\n",
      "0.02  /  0.41\n",
      "1644 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.57\n",
      "명령을 따랐는데 실패한 횟수 :  11\n",
      "평균 Reward :  0.28\n",
      "exploration rate :  1.4999999999737446e-07\n",
      "\n",
      "model2 updated 227448\n",
      "0.01  /  0.41\n",
      "1738 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.98\n",
      "명령을 따랐는데 실패한 횟수 :  22\n",
      "평균 Reward :  0.29\n",
      "exploration rate :  -0.0004998500000000031\n",
      "\n",
      "model2 updated 229462\n",
      "0.01  /  0.41\n",
      "2014 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.7\n",
      "명령을 따랐는데 실패한 횟수 :  22\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.0009998500000000035\n",
      "\n",
      "model2 updated 231621\n",
      "0.09  /  0.41\n",
      "2159 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.92\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.0014998000000000025\n",
      "\n",
      "model2 updated 234177\n",
      "0.11  /  0.41\n",
      "2556 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.69\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.44\n",
      "exploration rate :  -0.001999899999999999\n",
      "\n",
      "model2 updated 236379\n",
      "0.13  /  0.41\n",
      "2202 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.01\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.002499850000000005\n",
      "\n",
      "model2 updated 238656\n",
      "0.1  /  0.41\n",
      "2277 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.28\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.0029999500000000012\n",
      "\n",
      "model2 updated 240622\n",
      "0.01  /  0.41\n",
      "1966 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.49\n",
      "명령을 따랐는데 실패한 횟수 :  26\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.0034997999999999974\n",
      "\n",
      "model2 updated 242599\n",
      "0.02  /  0.41\n",
      "1977 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.62\n",
      "명령을 따랐는데 실패한 횟수 :  20\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.003999749999999996\n",
      "\n",
      "model2 updated 244703\n",
      "0.03  /  0.41\n",
      "2104 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.92\n",
      "명령을 따랐는데 실패한 횟수 :  10\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.004499799999999998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model2 updated 246478\n",
      "0.03  /  0.41\n",
      "1775 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.94\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.3\n",
      "exploration rate :  -0.0049999000000000016\n",
      "\n",
      "model2 updated 248189\n",
      "0.1  /  0.41\n",
      "1711 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.91\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.29\n",
      "exploration rate :  -0.005499900000000002\n",
      "\n",
      "model2 updated 250029\n",
      "0.05  /  0.41\n",
      "1840 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.06\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.005999950000000004\n",
      "\n",
      "model2 updated 251749\n",
      "0.07  /  0.41\n",
      "1720 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.76\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.29\n",
      "exploration rate :  -0.006499649999999996\n",
      "\n",
      "model2 updated 253492\n",
      "0.01  /  0.41\n",
      "1743 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.84\n",
      "명령을 따랐는데 실패한 횟수 :  36\n",
      "평균 Reward :  0.29\n",
      "exploration rate :  -0.006999950000000005\n",
      "\n",
      "model2 updated 255383\n",
      "0.05  /  0.41\n",
      "1891 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.22\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.007499850000000002\n",
      "\n",
      "model2 updated 257260\n",
      "0.05  /  0.41\n",
      "1877 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.28\n",
      "명령을 따랐는데 실패한 횟수 :  6\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.007999949999999999\n",
      "\n",
      "model2 updated 259236\n",
      "0.01  /  0.41\n",
      "1976 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.57\n",
      "명령을 따랐는데 실패한 횟수 :  40\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.008499649999999997\n",
      "\n",
      "model2 updated 261412\n",
      "0.09  /  0.41\n",
      "2176 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.07\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.008999899999999998\n",
      "\n",
      "model2 updated 263611\n",
      "0.05  /  0.41\n",
      "2199 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.15\n",
      "명령을 따랐는데 실패한 횟수 :  6\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.009499899999999999\n",
      "\n",
      "model2 updated 266263\n",
      "0.03  /  0.41\n",
      "2652 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.73\n",
      "명령을 따랐는데 실패한 횟수 :  13\n",
      "평균 Reward :  0.45\n",
      "exploration rate :  -0.00999995\n",
      "\n",
      "model2 updated 268657\n",
      "0.21  /  0.41\n",
      "2394 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.47\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.010499800000000004\n",
      "\n",
      "model2 updated 271046\n",
      "0.07  /  0.41\n",
      "2389 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.54\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.010999850000000005\n",
      "\n",
      "model2 updated 273193\n",
      "0.04  /  0.41\n",
      "2147 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.02\n",
      "명령을 따랐는데 실패한 횟수 :  9\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.0114999\n",
      "\n",
      "model2 updated 275639\n",
      "0.21  /  0.41\n",
      "2446 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.64\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.011999850000000006\n",
      "\n",
      "model2 updated 277761\n",
      "0.01  /  0.41\n",
      "2122 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.92\n",
      "명령을 따랐는데 실패한 횟수 :  24\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.01249985\n",
      "\n",
      "model2 updated 279831\n",
      "0.18  /  0.41\n",
      "2070 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.69\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.012999949999999996\n",
      "\n",
      "model2 updated 281486\n",
      "0.05  /  0.41\n",
      "1655 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.58\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.28\n",
      "exploration rate :  -0.013499749999999991\n",
      "\n",
      "model2 updated 283152\n",
      "0.05  /  0.41\n",
      "1666 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.64\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.28\n",
      "exploration rate :  -0.01399955\n",
      "\n",
      "model2 updated 284649\n",
      "0.04  /  0.41\n",
      "1497 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  1.96\n",
      "명령을 따랐는데 실패한 횟수 :  6\n",
      "평균 Reward :  0.25\n",
      "exploration rate :  -0.014499749999999992\n",
      "\n",
      "model2 updated 286272\n",
      "0.01  /  0.41\n",
      "1623 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.51\n",
      "명령을 따랐는데 실패한 횟수 :  30\n",
      "평균 Reward :  0.27\n",
      "exploration rate :  -0.014999799999999994\n",
      "\n",
      "model2 updated 288015\n",
      "0.01  /  0.41\n",
      "1743 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.86\n",
      "명령을 따랐는데 실패한 횟수 :  21\n",
      "평균 Reward :  0.3\n",
      "exploration rate :  -0.015499799999999994\n",
      "\n",
      "model2 updated 289619\n",
      "0.07  /  0.41\n",
      "1604 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.31\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.28\n",
      "exploration rate :  -0.01599985000000001\n",
      "\n",
      "model2 updated 291382\n",
      "0.02  /  0.41\n",
      "1763 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.91\n",
      "명령을 따랐는데 실패한 횟수 :  13\n",
      "평균 Reward :  0.3\n",
      "exploration rate :  -0.016499799999999995\n",
      "\n",
      "model2 updated 293514\n",
      "0.03  /  0.41\n",
      "2132 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.89\n",
      "명령을 따랐는데 실패한 횟수 :  13\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.016999900000000012\n",
      "\n",
      "model2 updated 295561\n",
      "0.06  /  0.41\n",
      "2047 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.82\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.01749995\n",
      "\n",
      "model2 updated 297679\n",
      "0.12  /  0.41\n",
      "2118 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.84\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.01799995\n",
      "\n",
      "model2 updated 299772\n",
      "0.09  /  0.41\n",
      "2093 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.86\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.01849995\n",
      "\n",
      "model2 updated 301828\n",
      "0.06  /  0.41\n",
      "2056 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.77\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.0189999\n",
      "\n",
      "model2 updated 303648\n",
      "0.1  /  0.41\n",
      "1820 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.1\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.019499650000000007\n",
      "\n",
      "model2 updated 305883\n",
      "0.03  /  0.41\n",
      "2235 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.18\n",
      "명령을 따랐는데 실패한 횟수 :  11\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.01999985\n",
      "\n",
      "model2 updated 308045\n",
      "0.05  /  0.41\n",
      "2162 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.97\n",
      "명령을 따랐는데 실패한 횟수 :  7\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.02049985\n",
      "\n",
      "model2 updated 310396\n",
      "0.01  /  0.41\n",
      "2351 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.44\n",
      "명령을 따랐는데 실패한 횟수 :  29\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.02099994999999999\n",
      "\n",
      "model2 updated 312536\n",
      "0.12  /  0.41\n",
      "2140 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.01\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.0214998\n",
      "\n",
      "model2 updated 314408\n",
      "0.01  /  0.41\n",
      "1872 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.28\n",
      "명령을 따랐는데 실패한 횟수 :  26\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.02199975\n",
      "\n",
      "model2 updated 315934\n",
      "0.02  /  0.41\n",
      "1526 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.14\n",
      "명령을 따랐는데 실패한 횟수 :  14\n",
      "평균 Reward :  0.26\n",
      "exploration rate :  -0.022499900000000003\n",
      "\n",
      "model2 updated 317724\n",
      "0.01  /  0.41\n",
      "1790 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.03\n",
      "명령을 따랐는데 실패한 횟수 :  47\n",
      "평균 Reward :  0.29\n",
      "exploration rate :  -0.0229998\n",
      "\n",
      "model2 updated 320076\n",
      "0.02  /  0.41\n",
      "2352 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.4\n",
      "명령을 따랐는데 실패한 횟수 :  23\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  -0.023499850000000003\n",
      "\n",
      "model2 updated 322281\n",
      "0.01  /  0.41\n",
      "2205 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.16\n",
      "명령을 따랐는데 실패한 횟수 :  33\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.023999900000000005\n",
      "\n",
      "model2 updated 324355\n",
      "0.36  /  0.41\n",
      "2074 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.73\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.024499900000000005\n",
      "\n",
      "model2 updated 326157\n",
      "0.08  /  0.41\n",
      "1802 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.03\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.024999800000000003\n",
      "\n",
      "model2 updated 327805\n",
      "0.01  /  0.41\n",
      "1648 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.5\n",
      "명령을 따랐는데 실패한 횟수 :  31\n",
      "평균 Reward :  0.28\n",
      "exploration rate :  -0.025499850000000004\n",
      "\n",
      "model2 updated 329504\n",
      "0.0  /  0.41\n",
      "1699 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.92\n",
      "명령을 따랐는데 실패한 횟수 :  80\n",
      "평균 Reward :  0.27\n",
      "exploration rate :  -0.025999750000000002\n",
      "\n",
      "model2 updated 331925\n",
      "0.14  /  0.41\n",
      "2421 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.47\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.0264997\n",
      "\n",
      "model2 updated 334009\n",
      "0.03  /  0.41\n",
      "2084 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.8\n",
      "명령을 따랐는데 실패한 횟수 :  12\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.026999800000000004\n",
      "\n",
      "model2 updated 336175\n",
      "0.05  /  0.41\n",
      "2166 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.89\n",
      "명령을 따랐는데 실패한 횟수 :  6\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.027499750000000003\n",
      "\n",
      "model2 updated 338087\n",
      "0.04  /  0.41\n",
      "1912 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.37\n",
      "명령을 따랐는데 실패한 횟수 :  7\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.027999900000000008\n",
      "\n",
      "model2 updated 339928\n",
      "0.01  /  0.41\n",
      "1841 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.19\n",
      "명령을 따랐는데 실패한 횟수 :  38\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.02849990000000001\n",
      "\n",
      "model2 updated 341533\n",
      "0.09  /  0.41\n",
      "1605 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.43\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.28\n",
      "exploration rate :  -0.02899990000000001\n",
      "\n",
      "model2 updated 343621\n",
      "0.01  /  0.41\n",
      "2088 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.85\n",
      "명령을 따랐는데 실패한 횟수 :  23\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.02949990000000001\n",
      "\n",
      "model2 updated 345728\n",
      "0.04  /  0.41\n",
      "2107 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.92\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.02999990000000001\n",
      "\n",
      "model2 updated 347875\n",
      "0.09  /  0.41\n",
      "2147 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.96\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.030499749999999992\n",
      "\n",
      "model2 updated 349783\n",
      "0.01  /  0.41\n",
      "1908 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.5\n",
      "명령을 따랐는데 실패한 횟수 :  23\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.03099990000000001\n",
      "\n",
      "model2 updated 351647\n",
      "0.05  /  0.41\n",
      "1864 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.35\n",
      "명령을 따랐는데 실패한 횟수 :  6\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.031499799999999994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model2 updated 354162\n",
      "0.04  /  0.41\n",
      "2515 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.71\n",
      "명령을 따랐는데 실패한 횟수 :  9\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  -0.03199990000000001\n",
      "\n",
      "model2 updated 356435\n",
      "0.13  /  0.41\n",
      "2273 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.24\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.032499799999999995\n",
      "\n",
      "model2 updated 358684\n",
      "0.13  /  0.41\n",
      "2249 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.21\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.032999799999999996\n",
      "\n",
      "model2 updated 360898\n",
      "0.08  /  0.41\n",
      "2214 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.0\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.033499799999999996\n",
      "\n",
      "model2 updated 363060\n",
      "0.37  /  0.41\n",
      "2162 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.06\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.033999749999999995\n",
      "\n",
      "model2 updated 365370\n",
      "0.07  /  0.41\n",
      "2310 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.23\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.0344998\n",
      "\n",
      "model2 updated 367775\n",
      "0.03  /  0.41\n",
      "2405 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.33\n",
      "명령을 따랐는데 실패한 횟수 :  15\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.0349999\n",
      "\n",
      "model2 updated 370173\n",
      "0.07  /  0.41\n",
      "2398 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.47\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.0354999\n",
      "\n",
      "model2 updated 372368\n",
      "0.19  /  0.41\n",
      "2195 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.05\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.03599995\n",
      "\n",
      "model2 updated 374382\n",
      "0.35  /  0.41\n",
      "2014 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.58\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.03649985\n",
      "\n",
      "model2 updated 376411\n",
      "0.03  /  0.41\n",
      "2029 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.78\n",
      "명령을 따랐는데 실패한 횟수 :  11\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.03699975\n",
      "\n",
      "model2 updated 378261\n",
      "0.08  /  0.41\n",
      "1850 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.2\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.03749985\n",
      "\n",
      "model2 updated 379822\n",
      "0.27  /  0.41\n",
      "1561 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.16\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.27\n",
      "exploration rate :  -0.0379998\n",
      "\n",
      "model2 updated 381737\n",
      "0.07  /  0.41\n",
      "1915 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.42\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.0384998\n",
      "\n",
      "model2 updated 383707\n",
      "0.11  /  0.41\n",
      "1970 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.53\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.03899975\n",
      "\n",
      "model2 updated 386096\n",
      "0.05  /  0.41\n",
      "2389 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.43\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.039499950000000006\n",
      "\n",
      "model2 updated 388303\n",
      "0.06  /  0.41\n",
      "2207 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.08\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.039999950000000006\n",
      "\n",
      "model2 updated 390316\n",
      "0.06  /  0.41\n",
      "2013 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.7\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.0404998\n",
      "\n",
      "model2 updated 392118\n",
      "0.16  /  0.41\n",
      "1802 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.97\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.04099995000000001\n",
      "\n",
      "model2 updated 393964\n",
      "0.05  /  0.41\n",
      "1846 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.13\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.041499900000000006\n",
      "\n",
      "model2 updated 395904\n",
      "0.33  /  0.41\n",
      "1940 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.37\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.041999700000000015\n",
      "\n",
      "model2 updated 398009\n",
      "0.18  /  0.41\n",
      "2105 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.86\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.04249990000000001\n",
      "\n",
      "model2 updated 399913\n",
      "0.16  /  0.41\n",
      "1904 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.3\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.042999700000000016\n",
      "\n",
      "model2 updated 401705\n",
      "0.15  /  0.41\n",
      "1792 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.06\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.04349995000000001\n",
      "\n",
      "model2 updated 403631\n",
      "0.17  /  0.41\n",
      "1926 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.41\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.043999750000000004\n",
      "\n",
      "model2 updated 405529\n",
      "0.16  /  0.41\n",
      "1898 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.44\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.04449995000000001\n",
      "\n",
      "model2 updated 407566\n",
      "0.12  /  0.41\n",
      "2037 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.68\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.04499995000000001\n",
      "\n",
      "model2 updated 409766\n",
      "0.13  /  0.41\n",
      "2200 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.96\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.04549990000000001\n",
      "\n",
      "model2 updated 411876\n",
      "0.18  /  0.41\n",
      "2110 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.77\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.04599985000000001\n",
      "\n",
      "model2 updated 413458\n",
      "0.14  /  0.41\n",
      "1582 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.26\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.27\n",
      "exploration rate :  -0.04649990000000001\n",
      "\n",
      "model2 updated 415246\n",
      "0.31  /  0.41\n",
      "1788 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.08\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.04699974999999999\n",
      "\n",
      "model2 updated 417042\n",
      "0.15  /  0.41\n",
      "1796 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.04\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.047499799999999995\n",
      "\n",
      "model2 updated 419069\n",
      "0.17  /  0.41\n",
      "2027 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.68\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.04799995000000001\n",
      "\n",
      "model2 updated 421311\n",
      "0.1  /  0.41\n",
      "2242 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.11\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.04849990000000001\n",
      "\n",
      "model2 updated 423130\n",
      "0.16  /  0.41\n",
      "1819 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.04\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.048999950000000014\n",
      "\n",
      "model2 updated 424944\n",
      "0.16  /  0.41\n",
      "1814 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.13\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.04949985\n",
      "\n",
      "model2 updated 426607\n",
      "0.14  /  0.41\n",
      "1663 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.46\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.29\n",
      "exploration rate :  -0.0499999\n",
      "\n",
      "model2 updated 428146\n",
      "0.13  /  0.41\n",
      "1539 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.07\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.26\n",
      "exploration rate :  -0.050499749999999996\n",
      "\n",
      "model2 updated 429870\n",
      "0.1  /  0.41\n",
      "1724 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.86\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.29\n",
      "exploration rate :  -0.05099995\n",
      "\n",
      "model2 updated 431714\n",
      "0.04  /  0.41\n",
      "1844 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.13\n",
      "명령을 따랐는데 실패한 횟수 :  7\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.051499600000000006\n",
      "\n",
      "model2 updated 433565\n",
      "0.32  /  0.41\n",
      "1851 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.18\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.05199995\n",
      "\n",
      "model2 updated 435396\n",
      "0.06  /  0.41\n",
      "1831 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.12\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.05249985\n",
      "\n",
      "model2 updated 437534\n",
      "0.05  /  0.41\n",
      "2138 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.93\n",
      "명령을 따랐는데 실패한 횟수 :  7\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.05299985\n",
      "\n",
      "model2 updated 439697\n",
      "0.09  /  0.41\n",
      "2163 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.99\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.05349975\n",
      "\n",
      "model2 updated 441496\n",
      "0.1  /  0.41\n",
      "1799 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.97\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.0539999\n",
      "\n",
      "model2 updated 443720\n",
      "0.1  /  0.41\n",
      "2224 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.08\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.05449965000000001\n",
      "\n",
      "model2 updated 445794\n",
      "0.09  /  0.41\n",
      "2074 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.79\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.05499985\n",
      "\n",
      "model2 updated 448004\n",
      "0.19  /  0.41\n",
      "2210 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.05\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.055499950000000006\n",
      "\n",
      "model2 updated 450170\n",
      "0.19  /  0.41\n",
      "2166 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.02\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.0559998\n",
      "\n",
      "model2 updated 452210\n",
      "0.09  /  0.41\n",
      "2040 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.73\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.05649975\n",
      "\n",
      "model2 updated 454101\n",
      "0.11  /  0.41\n",
      "1891 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.38\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.05699945000000001\n",
      "\n",
      "model2 updated 455974\n",
      "0.16  /  0.41\n",
      "1873 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.18\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.05749965\n",
      "\n",
      "model2 updated 457925\n",
      "0.07  /  0.41\n",
      "1951 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.59\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.057999850000000006\n",
      "\n",
      "model2 updated 459857\n",
      "0.06  /  0.41\n",
      "1932 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.43\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.05849990000000001\n",
      "\n",
      "model2 updated 461634\n",
      "0.04  /  0.41\n",
      "1777 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.95\n",
      "명령을 따랐는데 실패한 횟수 :  7\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.05899995000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model2 updated 463506\n",
      "0.02  /  0.41\n",
      "1872 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.29\n",
      "명령을 따랐는데 실패한 횟수 :  16\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.059499750000000004\n",
      "\n",
      "model2 updated 465449\n",
      "0.04  /  0.41\n",
      "1943 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.48\n",
      "명령을 따랐는데 실패한 횟수 :  7\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.05999985000000001\n",
      "\n",
      "model2 updated 467321\n",
      "0.11  /  0.41\n",
      "1872 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.42\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.060499800000000006\n",
      "\n",
      "model2 updated 469109\n",
      "0.15  /  0.41\n",
      "1788 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.14\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.06099985000000001\n",
      "\n",
      "model2 updated 470943\n",
      "0.08  /  0.41\n",
      "1834 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.08\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.06149995000000001\n",
      "\n",
      "model2 updated 473199\n",
      "0.19  /  0.41\n",
      "2256 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.14\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.061999799999999994\n",
      "\n",
      "model2 updated 475499\n",
      "0.1  /  0.41\n",
      "2300 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.27\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.06249990000000001\n",
      "\n",
      "model2 updated 477854\n",
      "0.03  /  0.41\n",
      "2355 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.3\n",
      "명령을 따랐는데 실패한 횟수 :  12\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  -0.06299995000000001\n",
      "\n",
      "model2 updated 480264\n",
      "0.07  /  0.41\n",
      "2410 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.49\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.06349995000000001\n",
      "\n",
      "model2 updated 482514\n",
      "0.39  /  0.41\n",
      "2250 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.09\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.06399985\n",
      "\n",
      "model2 updated 484930\n",
      "0.14  /  0.41\n",
      "2416 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.49\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.0644998\n",
      "\n",
      "model2 updated 486866\n",
      "0.17  /  0.41\n",
      "1936 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.69\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.06499975\n",
      "\n",
      "model2 updated 488979\n",
      "0.03  /  0.41\n",
      "2113 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.87\n",
      "명령을 따랐는데 실패한 횟수 :  12\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.06549970000000001\n",
      "\n",
      "model2 updated 491727\n",
      "0.12  /  0.41\n",
      "2748 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.94\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.47\n",
      "exploration rate :  -0.0659999\n",
      "\n",
      "model2 updated 494234\n",
      "0.03  /  0.41\n",
      "2507 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.59\n",
      "명령을 따랐는데 실패한 횟수 :  12\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  -0.06649985\n",
      "\n",
      "model2 updated 496214\n",
      "0.17  /  0.41\n",
      "1980 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.39\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.06699995\n",
      "\n",
      "model2 updated 498187\n",
      "0.08  /  0.41\n",
      "1973 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.5\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.0674999\n",
      "\n",
      "model2 updated 499878\n",
      "0.29  /  0.41\n",
      "1691 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.75\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.29\n",
      "exploration rate :  -0.06799985\n",
      "\n",
      "model2 updated 501911\n",
      "0.07  /  0.41\n",
      "2033 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.53\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.06849985\n",
      "\n",
      "model2 updated 503742\n",
      "0.06  /  0.41\n",
      "1831 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.15\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.06899985\n",
      "\n",
      "model2 updated 505702\n",
      "0.06  /  0.41\n",
      "1960 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.57\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.06949985\n",
      "\n",
      "model2 updated 507421\n",
      "0.1  /  0.41\n",
      "1719 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.78\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.3\n",
      "exploration rate :  -0.0699999\n",
      "\n",
      "model2 updated 509487\n",
      "0.04  /  0.41\n",
      "2066 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.77\n",
      "명령을 따랐는데 실패한 횟수 :  7\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.07049920000000001\n",
      "\n",
      "model2 updated 511508\n",
      "0.35  /  0.41\n",
      "2021 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.63\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.07099975\n",
      "\n",
      "model2 updated 513727\n",
      "0.13  /  0.41\n",
      "2219 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.19\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.0714998\n",
      "\n",
      "model2 updated 515726\n",
      "0.11  /  0.41\n",
      "1999 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.71\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.07199985\n",
      "\n",
      "model2 updated 517989\n",
      "0.13  /  0.41\n",
      "2263 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.37\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.07249995000000001\n",
      "\n",
      "model2 updated 519804\n",
      "0.16  /  0.41\n",
      "1815 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.14\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.0729998\n",
      "\n",
      "model2 updated 521740\n",
      "0.11  /  0.41\n",
      "1936 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.4\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.07349970000000002\n",
      "\n",
      "model2 updated 524031\n",
      "0.1  /  0.41\n",
      "2291 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.32\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.07399990000000001\n",
      "\n",
      "model2 updated 525977\n",
      "0.17  /  0.41\n",
      "1946 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.4\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.0744998\n",
      "\n",
      "model2 updated 527737\n",
      "0.15  /  0.41\n",
      "1760 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.83\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.3\n",
      "exploration rate :  -0.0749998\n",
      "\n",
      "model2 updated 529634\n",
      "0.33  /  0.41\n",
      "1897 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.36\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.0754999\n",
      "\n",
      "model2 updated 531750\n",
      "0.12  /  0.41\n",
      "2116 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.9\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.07599995\n",
      "\n",
      "model2 updated 533985\n",
      "0.38  /  0.41\n",
      "2235 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.06\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.07649995\n",
      "\n",
      "model2 updated 536157\n",
      "0.19  /  0.41\n",
      "2172 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.97\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.0769999\n",
      "\n",
      "model2 updated 538129\n",
      "0.17  /  0.41\n",
      "1972 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.47\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.0774999\n",
      "\n",
      "model2 updated 540204\n",
      "0.09  /  0.41\n",
      "2075 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.73\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.07799985\n",
      "\n",
      "model2 updated 542365\n",
      "0.07  /  0.41\n",
      "2161 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.98\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.07849985\n",
      "\n",
      "model2 updated 544407\n",
      "0.35  /  0.41\n",
      "2042 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.7\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.0789998\n",
      "\n",
      "model2 updated 546299\n",
      "0.33  /  0.41\n",
      "1892 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.39\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.0794998\n",
      "\n",
      "model2 updated 548438\n",
      "0.18  /  0.41\n",
      "2139 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.87\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.0799998\n",
      "\n",
      "model2 updated 550557\n",
      "0.18  /  0.41\n",
      "2119 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.76\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.0804999\n",
      "\n",
      "model2 updated 552478\n",
      "0.07  /  0.41\n",
      "1921 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.44\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.08099954999999999\n",
      "\n",
      "model2 updated 554479\n",
      "0.17  /  0.41\n",
      "2001 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.55\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.08149985\n",
      "\n",
      "model2 updated 556614\n",
      "0.12  /  0.41\n",
      "2135 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.97\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.08199995\n",
      "\n",
      "model2 updated 558641\n",
      "0.18  /  0.41\n",
      "2027 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.6\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.0824999\n",
      "\n",
      "model2 updated 560936\n",
      "0.13  /  0.41\n",
      "2295 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.25\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.08299985\n",
      "\n",
      "model2 updated 563143\n",
      "0.38  /  0.41\n",
      "2207 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.09\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.08349995\n",
      "\n",
      "model2 updated 565343\n",
      "0.06  /  0.41\n",
      "2200 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.1\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.08399980000000003\n",
      "\n",
      "model2 updated 567414\n",
      "0.04  /  0.41\n",
      "2071 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.77\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.08449995\n",
      "\n",
      "model2 updated 569602\n",
      "0.09  /  0.41\n",
      "2188 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.04\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.0849999\n",
      "\n",
      "model2 updated 571667\n",
      "0.12  /  0.41\n",
      "2065 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.81\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.08549985\n",
      "\n",
      "model2 updated 573750\n",
      "0.36  /  0.41\n",
      "2083 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.79\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.08599995\n",
      "\n",
      "model2 updated 575527\n",
      "0.15  /  0.41\n",
      "1777 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.92\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.08649985\n",
      "\n",
      "model2 updated 577651\n",
      "0.01  /  0.41\n",
      "2124 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.87\n",
      "명령을 따랐는데 실패한 횟수 :  37\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.08699995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model2 updated 579658\n",
      "0.01  /  0.41\n",
      "2007 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.65\n",
      "명령을 따랐는데 실패한 횟수 :  57\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.0874998\n",
      "\n",
      "model2 updated 581861\n",
      "0.08  /  0.41\n",
      "2203 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.05\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.0879997\n",
      "\n",
      "model2 updated 584262\n",
      "0.1  /  0.41\n",
      "2401 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.38\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.0884998\n",
      "\n",
      "model2 updated 586303\n",
      "0.09  /  0.41\n",
      "2041 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.81\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.08899975\n",
      "\n",
      "model2 updated 588286\n",
      "0.07  /  0.41\n",
      "1983 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.56\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.08949975\n",
      "\n",
      "model2 updated 590541\n",
      "0.02  /  0.41\n",
      "2255 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.12\n",
      "명령을 따랐는데 실패한 횟수 :  24\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.08999975\n",
      "\n",
      "model2 updated 592779\n",
      "0.02  /  0.41\n",
      "2238 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.07\n",
      "명령을 따랐는데 실패한 횟수 :  22\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.0904997\n",
      "\n",
      "model2 updated 595013\n",
      "0.01  /  0.41\n",
      "2234 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.14\n",
      "명령을 따랐는데 실패한 횟수 :  62\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.0909998\n",
      "\n",
      "model2 updated 597486\n",
      "0.05  /  0.41\n",
      "2473 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.57\n",
      "명령을 따랐는데 실패한 횟수 :  7\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.09149975\n",
      "\n",
      "model2 updated 600170\n",
      "0.02  /  0.41\n",
      "2684 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.94\n",
      "명령을 따랐는데 실패한 횟수 :  18\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  -0.09199995000000001\n",
      "\n",
      "model2 updated 602435\n",
      "0.06  /  0.41\n",
      "2265 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.28\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.09249985000000001\n",
      "\n",
      "model2 updated 604666\n",
      "0.04  /  0.41\n",
      "2231 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.14\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.09299985000000001\n",
      "\n",
      "model2 updated 607108\n",
      "0.08  /  0.41\n",
      "2442 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.5\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.09349980000000001\n",
      "\n",
      "model2 updated 609594\n",
      "0.11  /  0.41\n",
      "2486 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.44\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  -0.09399985000000001\n",
      "\n",
      "model2 updated 612458\n",
      "0.12  /  0.41\n",
      "2864 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.09\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.49\n",
      "exploration rate :  -0.09449989999999998\n",
      "\n",
      "model2 updated 615131\n",
      "0.15  /  0.41\n",
      "2673 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.89\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  -0.09499985000000001\n",
      "\n",
      "model2 updated 617289\n",
      "0.07  /  0.41\n",
      "2158 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.01\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.09549995000000001\n",
      "\n",
      "model2 updated 619250\n",
      "0.07  /  0.41\n",
      "1961 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.54\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.09599980000000001\n",
      "\n",
      "model2 updated 621216\n",
      "0.03  /  0.41\n",
      "1966 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.49\n",
      "명령을 따랐는데 실패한 횟수 :  11\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.09649995000000001\n",
      "\n",
      "model2 updated 623072\n",
      "0.01  /  0.41\n",
      "1856 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.29\n",
      "명령을 따랐는데 실패한 횟수 :  53\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.09699989999999999\n",
      "\n",
      "model2 updated 625207\n",
      "0.03  /  0.41\n",
      "2135 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.9\n",
      "명령을 따랐는데 실패한 횟수 :  13\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.09749989999999999\n",
      "\n",
      "model2 updated 628034\n",
      "0.0  /  0.41\n",
      "2827 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.12\n",
      "명령을 따랐는데 실패한 횟수 :  117\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  -0.09799995000000002\n",
      "\n",
      "model2 updated 630801\n",
      "0.24  /  0.41\n",
      "2767 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.91\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.47\n",
      "exploration rate :  -0.09849989999999999\n",
      "\n",
      "model2 updated 633305\n",
      "0.14  /  0.41\n",
      "2504 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.56\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  -0.09899989999999999\n",
      "\n",
      "model2 updated 635410\n",
      "0.36  /  0.41\n",
      "2105 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.85\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.09949970000000001\n",
      "\n",
      "model2 updated 637645\n",
      "0.08  /  0.41\n",
      "2235 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.15\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.09999964999999998\n",
      "\n",
      "model2 updated 639822\n",
      "0.02  /  0.41\n",
      "2177 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.04\n",
      "명령을 따랐는데 실패한 횟수 :  22\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.10049989999999999\n",
      "\n",
      "model2 updated 642010\n",
      "0.38  /  0.41\n",
      "2188 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.97\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.10099989999999999\n",
      "\n",
      "model2 updated 644341\n",
      "0.0  /  0.41\n",
      "2331 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.37\n",
      "명령을 따랐는데 실패한 횟수 :  102\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.10149985000000002\n",
      "\n",
      "model2 updated 646184\n",
      "0.0  /  0.41\n",
      "1843 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.23\n",
      "명령을 따랐는데 실패한 횟수 :  148\n",
      "평균 Reward :  0.29\n",
      "exploration rate :  -0.10199985000000002\n",
      "\n",
      "model2 updated 648018\n",
      "0.03  /  0.41\n",
      "1834 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.11\n",
      "명령을 따랐는데 실패한 횟수 :  8\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.10249984999999999\n",
      "\n",
      "model2 updated 649883\n",
      "0.16  /  0.41\n",
      "1865 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.3\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.10299989999999999\n",
      "\n",
      "model2 updated 651841\n",
      "0.33  /  0.41\n",
      "1958 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.38\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.10349995000000002\n",
      "\n",
      "model2 updated 653760\n",
      "0.11  /  0.41\n",
      "1919 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.41\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.10399960000000001\n",
      "\n",
      "model2 updated 656152\n",
      "0.07  /  0.41\n",
      "2392 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.39\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.10449984999999999\n",
      "\n",
      "model2 updated 658555\n",
      "0.07  /  0.41\n",
      "2403 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.37\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.1049999\n",
      "\n",
      "model2 updated 660780\n",
      "0.19  /  0.41\n",
      "2225 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.08\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.1054999\n",
      "\n",
      "model2 updated 663154\n",
      "0.21  /  0.41\n",
      "2374 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.5\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.10599970000000002\n",
      "\n",
      "model2 updated 665559\n",
      "0.14  /  0.41\n",
      "2405 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.44\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.10649985\n",
      "\n",
      "model2 updated 668411\n",
      "0.49  /  0.41\n",
      "2852 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.11\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.49\n",
      "exploration rate :  -0.1069999\n",
      "best model saved\n",
      "\n",
      "model2 updated 670534\n",
      "0.09  /  0.49\n",
      "2123 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.99\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.10749970000000002\n",
      "\n",
      "model2 updated 672375\n",
      "0.08  /  0.49\n",
      "1841 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.2\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.10799980000000002\n",
      "\n",
      "model2 updated 674280\n",
      "0.11  /  0.49\n",
      "1905 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.45\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.10849995\n",
      "\n",
      "model2 updated 676281\n",
      "0.17  /  0.49\n",
      "2001 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.6\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.10899995\n",
      "\n",
      "model2 updated 678445\n",
      "0.37  /  0.49\n",
      "2164 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.94\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.10949990000000002\n",
      "\n",
      "model2 updated 680964\n",
      "0.11  /  0.49\n",
      "2519 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.62\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  -0.10999990000000003\n",
      "\n",
      "model2 updated 683375\n",
      "0.08  /  0.49\n",
      "2411 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.5\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.11049985\n",
      "\n",
      "model2 updated 685837\n",
      "0.14  /  0.49\n",
      "2462 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.61\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.11099985\n",
      "\n",
      "model2 updated 688206\n",
      "0.1  /  0.49\n",
      "2369 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.34\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.11149985\n",
      "\n",
      "model2 updated 690436\n",
      "0.19  /  0.49\n",
      "2230 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.08\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.11199975\n",
      "\n",
      "model2 updated 692767\n",
      "0.13  /  0.49\n",
      "2331 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.22\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  -0.11249980000000002\n",
      "\n",
      "model2 updated 695194\n",
      "0.42  /  0.49\n",
      "2427 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.4\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.11299990000000003\n",
      "\n",
      "model2 updated 697793\n",
      "0.45  /  0.49\n",
      "2599 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.76\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.45\n",
      "exploration rate :  -0.11349990000000003\n",
      "\n",
      "model2 updated 700234\n",
      "0.42  /  0.49\n",
      "2441 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.44\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.11399985\n",
      "\n",
      "model2 updated 702483\n",
      "0.39  /  0.49\n",
      "2249 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.11\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.11449990000000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model2 updated 705100\n",
      "0.23  /  0.49\n",
      "2617 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.8\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.45\n",
      "exploration rate :  -0.11499990000000003\n",
      "\n",
      "model2 updated 707543\n",
      "0.08  /  0.49\n",
      "2443 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.51\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.11549980000000003\n",
      "\n",
      "model2 updated 709711\n",
      "0.19  /  0.49\n",
      "2168 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.99\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.11599995\n",
      "\n",
      "model2 updated 711841\n",
      "0.37  /  0.49\n",
      "2130 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.0\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.11649995\n",
      "\n",
      "model2 updated 714381\n",
      "0.09  /  0.49\n",
      "2540 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.65\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.44\n",
      "exploration rate :  -0.11699985\n",
      "\n",
      "model2 updated 716458\n",
      "0.18  /  0.49\n",
      "2077 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.79\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.1174997\n",
      "\n",
      "model2 updated 718656\n",
      "0.19  /  0.49\n",
      "2198 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.99\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.1179997\n",
      "\n",
      "model2 updated 720788\n",
      "0.12  /  0.49\n",
      "2132 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.93\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.11849985\n",
      "\n",
      "model2 updated 723191\n",
      "0.14  /  0.49\n",
      "2403 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.47\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.11899985\n",
      "\n",
      "model2 updated 725346\n",
      "0.19  /  0.49\n",
      "2155 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.93\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.1194997\n",
      "\n",
      "model2 updated 727465\n",
      "0.12  /  0.49\n",
      "2119 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.88\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.11999995000000001\n",
      "\n",
      "model2 updated 729523\n",
      "0.12  /  0.49\n",
      "2058 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.85\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.12049985\n",
      "\n",
      "model2 updated 731948\n",
      "0.08  /  0.49\n",
      "2425 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.43\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.12099985\n",
      "\n",
      "model2 updated 734191\n",
      "0.19  /  0.49\n",
      "2243 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.13\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.12149995000000001\n",
      "\n",
      "model2 updated 736446\n",
      "0.19  /  0.49\n",
      "2255 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.25\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.12199985\n",
      "\n",
      "model2 updated 738926\n",
      "0.43  /  0.49\n",
      "2480 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.46\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  -0.12249995000000001\n",
      "\n",
      "model2 updated 741096\n",
      "0.19  /  0.49\n",
      "2170 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.02\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.12299985000000001\n",
      "\n",
      "model2 updated 743226\n",
      "0.37  /  0.49\n",
      "2130 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.9\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.12349995000000001\n",
      "\n",
      "model2 updated 745771\n",
      "0.22  /  0.49\n",
      "2545 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.61\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.44\n",
      "exploration rate :  -0.12399995000000001\n",
      "\n",
      "model2 updated 748056\n",
      "0.07  /  0.49\n",
      "2285 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.16\n",
      "명령을 따랐는데 실패한 횟수 :  5\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.12449975\n",
      "\n",
      "model2 updated 750057\n",
      "0.17  /  0.49\n",
      "2001 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.6\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.12499980000000001\n",
      "\n",
      "model2 updated 752144\n",
      "0.18  /  0.49\n",
      "2087 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.82\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.12549985000000002\n",
      "\n",
      "model2 updated 754019\n",
      "0.32  /  0.49\n",
      "1875 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.26\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.12599975000000002\n",
      "\n",
      "model2 updated 756100\n",
      "0.12  /  0.49\n",
      "2081 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.91\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.12649975000000002\n",
      "\n",
      "model2 updated 758339\n",
      "0.38  /  0.49\n",
      "2239 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.08\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.12699975000000002\n",
      "\n",
      "model2 updated 760823\n",
      "0.21  /  0.49\n",
      "2484 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.5\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  -0.1274998\n",
      "\n",
      "model2 updated 763285\n",
      "0.11  /  0.49\n",
      "2462 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.46\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.1279999\n",
      "\n",
      "model2 updated 765587\n",
      "0.13  /  0.49\n",
      "2302 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.27\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  -0.12849995000000003\n",
      "\n",
      "model2 updated 767890\n",
      "0.13  /  0.49\n",
      "2303 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.21\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  -0.1289999\n",
      "\n",
      "model2 updated 770012\n",
      "0.37  /  0.49\n",
      "2122 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.86\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.12949985000000003\n",
      "\n",
      "model2 updated 772282\n",
      "0.2  /  0.49\n",
      "2270 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.2\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.1299999\n",
      "\n",
      "model2 updated 774493\n",
      "0.38  /  0.49\n",
      "2211 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.06\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.13049985000000003\n",
      "\n",
      "model2 updated 776874\n",
      "0.2  /  0.49\n",
      "2381 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.36\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.1309999\n",
      "\n",
      "model2 updated 779521\n",
      "0.46  /  0.49\n",
      "2647 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.77\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  -0.1314999\n",
      "\n",
      "model2 updated 781998\n",
      "0.21  /  0.49\n",
      "2477 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.58\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  -0.13199974999999997\n",
      "\n",
      "model2 updated 784461\n",
      "0.42  /  0.49\n",
      "2463 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.53\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.1324999\n",
      "\n",
      "model2 updated 787075\n",
      "0.09  /  0.49\n",
      "2614 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.89\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.45\n",
      "exploration rate :  -0.13299974999999997\n",
      "\n",
      "model2 updated 789278\n",
      "0.1  /  0.49\n",
      "2203 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.1\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.1334999\n",
      "\n",
      "model2 updated 791000\n",
      "0.3  /  0.49\n",
      "1722 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.86\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.3\n",
      "exploration rate :  -0.1339999\n",
      "\n",
      "model2 updated 792735\n",
      "0.15  /  0.49\n",
      "1735 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.96\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.3\n",
      "exploration rate :  -0.13449974999999997\n",
      "\n",
      "model2 updated 794897\n",
      "0.37  /  0.49\n",
      "2162 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.04\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.13499974999999997\n",
      "\n",
      "model2 updated 797023\n",
      "0.37  /  0.49\n",
      "2126 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.89\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.1354999\n",
      "\n",
      "model2 updated 799587\n",
      "0.15  /  0.49\n",
      "2564 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.83\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.44\n",
      "exploration rate :  -0.13599995000000004\n",
      "\n",
      "model2 updated 802002\n",
      "0.21  /  0.49\n",
      "2415 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.5\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.13649974999999998\n",
      "\n",
      "model2 updated 803964\n",
      "0.34  /  0.49\n",
      "1962 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.43\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.13699974999999998\n",
      "\n",
      "model2 updated 806618\n",
      "0.15  /  0.49\n",
      "2654 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.85\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  -0.1374999\n",
      "\n",
      "model2 updated 809019\n",
      "0.21  /  0.49\n",
      "2401 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.44\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.1379999\n",
      "\n",
      "model2 updated 811278\n",
      "0.39  /  0.49\n",
      "2259 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.13\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.13849974999999998\n",
      "\n",
      "model2 updated 813353\n",
      "0.36  /  0.49\n",
      "2075 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.79\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.13899974999999998\n",
      "\n",
      "model2 updated 815656\n",
      "0.4  /  0.49\n",
      "2303 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.25\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  -0.13949974999999998\n",
      "\n",
      "model2 updated 818142\n",
      "0.14  /  0.49\n",
      "2486 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.59\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  -0.13999994999999998\n",
      "\n",
      "model2 updated 820614\n",
      "0.11  /  0.49\n",
      "2472 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.59\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.14049974999999998\n",
      "\n",
      "model2 updated 822786\n",
      "0.37  /  0.49\n",
      "2172 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.94\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.1409998\n",
      "\n",
      "model2 updated 825187\n",
      "0.21  /  0.49\n",
      "2401 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.44\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.1414999\n",
      "\n",
      "model2 updated 827728\n",
      "0.22  /  0.49\n",
      "2541 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.67\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.44\n",
      "exploration rate :  -0.1419998\n",
      "\n",
      "model2 updated 830411\n",
      "0.23  /  0.49\n",
      "2683 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.83\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  -0.14249984999999998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model2 updated 832916\n",
      "0.43  /  0.49\n",
      "2505 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.54\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  -0.14299984999999998\n",
      "\n",
      "model2 updated 835134\n",
      "0.13  /  0.49\n",
      "2218 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.11\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.14349974999999998\n",
      "\n",
      "model2 updated 837251\n",
      "0.37  /  0.49\n",
      "2117 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.86\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.14399974999999998\n",
      "\n",
      "model2 updated 839597\n",
      "0.4  /  0.49\n",
      "2346 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.48\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  -0.14449984999999999\n",
      "\n",
      "model2 updated 841830\n",
      "0.13  /  0.49\n",
      "2233 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.03\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.14499984999999999\n",
      "\n",
      "model2 updated 843897\n",
      "0.35  /  0.49\n",
      "2067 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.85\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.1454997\n",
      "\n",
      "model2 updated 846053\n",
      "0.37  /  0.49\n",
      "2156 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.87\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.14599990000000002\n",
      "\n",
      "model2 updated 848492\n",
      "0.14  /  0.49\n",
      "2439 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.56\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.14649990000000002\n",
      "\n",
      "model2 updated 850975\n",
      "0.43  /  0.49\n",
      "2483 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.69\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  -0.1469998\n",
      "\n",
      "model2 updated 853421\n",
      "0.42  /  0.49\n",
      "2446 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.5\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.14749974999999999\n",
      "\n",
      "model2 updated 856197\n",
      "0.16  /  0.49\n",
      "2776 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.01\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.48\n",
      "exploration rate :  -0.14799995\n",
      "\n",
      "model2 updated 858695\n",
      "0.43  /  0.49\n",
      "2498 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.57\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.43\n",
      "exploration rate :  -0.14849985\n",
      "\n",
      "model2 updated 860733\n",
      "0.18  /  0.49\n",
      "2038 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.82\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.14899985\n",
      "\n",
      "model2 updated 862560\n",
      "0.16  /  0.49\n",
      "1827 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.15\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.14949980000000002\n",
      "\n",
      "model2 updated 864206\n",
      "0.04  /  0.49\n",
      "1646 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  2.58\n",
      "명령을 따랐는데 실패한 횟수 :  6\n",
      "평균 Reward :  0.28\n",
      "exploration rate :  -0.14999965000000004\n",
      "\n",
      "model2 updated 866039\n",
      "0.31  /  0.49\n",
      "1833 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.12\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.15049980000000002\n",
      "\n",
      "model2 updated 868110\n",
      "0.18  /  0.49\n",
      "2071 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.77\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.15099975\n",
      "\n",
      "model2 updated 870313\n",
      "0.19  /  0.49\n",
      "2203 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.98\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.15149990000000002\n",
      "\n",
      "model2 updated 872592\n",
      "0.39  /  0.49\n",
      "2279 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.13\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.15199975\n",
      "\n",
      "model2 updated 874815\n",
      "0.19  /  0.49\n",
      "2223 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.07\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.15249990000000002\n",
      "\n",
      "model2 updated 876982\n",
      "0.19  /  0.49\n",
      "2167 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.0\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.15299970000000002\n",
      "\n",
      "model2 updated 879036\n",
      "0.35  /  0.49\n",
      "2054 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.67\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.15349990000000002\n",
      "\n",
      "model2 updated 881343\n",
      "0.4  /  0.49\n",
      "2307 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.14\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  -0.15399995\n",
      "\n",
      "model2 updated 883303\n",
      "0.08  /  0.49\n",
      "1960 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.47\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.15449995\n",
      "\n",
      "model2 updated 885356\n",
      "0.35  /  0.49\n",
      "2053 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.75\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.15499990000000002\n",
      "\n",
      "model2 updated 887432\n",
      "0.18  /  0.49\n",
      "2076 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.8\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.15549990000000002\n",
      "\n",
      "model2 updated 889396\n",
      "0.34  /  0.49\n",
      "1964 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.45\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.15599995\n",
      "\n",
      "model2 updated 891948\n",
      "0.11  /  0.49\n",
      "2552 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.66\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.44\n",
      "exploration rate :  -0.15649995\n",
      "\n",
      "model2 updated 894643\n",
      "0.46  /  0.49\n",
      "2695 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.92\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  -0.15699990000000003\n",
      "\n",
      "model2 updated 897328\n",
      "0.23  /  0.49\n",
      "2685 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.8\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  -0.15749980000000002\n",
      "\n",
      "model2 updated 899774\n",
      "0.08  /  0.49\n",
      "2446 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.49\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.15799985\n",
      "\n",
      "model2 updated 901774\n",
      "0.34  /  0.49\n",
      "2000 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.67\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.15849980000000002\n",
      "\n",
      "model2 updated 903941\n",
      "0.19  /  0.49\n",
      "2167 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.92\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.15899980000000002\n",
      "\n",
      "model2 updated 906267\n",
      "0.13  /  0.49\n",
      "2326 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.23\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  -0.15949990000000003\n",
      "\n",
      "model2 updated 908407\n",
      "0.37  /  0.49\n",
      "2140 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.96\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.15999990000000003\n",
      "\n",
      "model2 updated 910396\n",
      "0.11  /  0.49\n",
      "1989 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.64\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.16049980000000003\n",
      "\n",
      "model2 updated 912456\n",
      "0.18  /  0.49\n",
      "2060 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.78\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.16099975\n",
      "\n",
      "model2 updated 914712\n",
      "0.1  /  0.49\n",
      "2256 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.22\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.16149990000000003\n",
      "\n",
      "model2 updated 916969\n",
      "0.39  /  0.49\n",
      "2257 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.21\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.16199970000000002\n",
      "\n",
      "model2 updated 919390\n",
      "0.14  /  0.49\n",
      "2421 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.53\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.16249995\n",
      "\n",
      "model2 updated 921674\n",
      "0.39  /  0.49\n",
      "2284 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.21\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.16299975\n",
      "\n",
      "model2 updated 924283\n",
      "0.15  /  0.49\n",
      "2609 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.7\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.45\n",
      "exploration rate :  -0.16349985\n",
      "\n",
      "model2 updated 926727\n",
      "0.08  /  0.49\n",
      "2444 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.57\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.16399985\n",
      "\n",
      "model2 updated 929024\n",
      "0.2  /  0.49\n",
      "2297 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.32\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.16449960000000002\n",
      "\n",
      "model2 updated 931672\n",
      "0.46  /  0.49\n",
      "2648 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.82\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  -0.16499995\n",
      "\n",
      "model2 updated 934453\n",
      "0.12  /  0.49\n",
      "2781 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.93\n",
      "명령을 따랐는데 실패한 횟수 :  3\n",
      "평균 Reward :  0.47\n",
      "exploration rate :  -0.16549995\n",
      "\n",
      "model2 updated 936837\n",
      "0.14  /  0.49\n",
      "2384 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.35\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.16599985\n",
      "\n",
      "model2 updated 939142\n",
      "0.13  /  0.49\n",
      "2305 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.31\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  -0.16649980000000003\n",
      "\n",
      "model2 updated 941562\n",
      "0.42  /  0.49\n",
      "2420 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.47\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.42\n",
      "exploration rate :  -0.16699980000000003\n",
      "\n",
      "model2 updated 943966\n",
      "0.14  /  0.49\n",
      "2404 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.36\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.16749975\n",
      "\n",
      "model2 updated 946029\n",
      "0.35  /  0.49\n",
      "2063 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.66\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.16799975\n",
      "\n",
      "model2 updated 947992\n",
      "0.34  /  0.49\n",
      "1963 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.47\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.16849990000000004\n",
      "\n",
      "model2 updated 950334\n",
      "0.13  /  0.49\n",
      "2342 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.37\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  -0.16899995\n",
      "\n",
      "model2 updated 952344\n",
      "0.07  /  0.49\n",
      "2010 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.69\n",
      "명령을 따랐는데 실패한 횟수 :  4\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.16949980000000003\n",
      "\n",
      "model2 updated 954415\n",
      "0.0  /  0.49\n",
      "2071 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.97\n",
      "명령을 따랐는데 실패한 횟수 :  158\n",
      "평균 Reward :  0.33\n",
      "exploration rate :  -0.16999995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model2 updated 956551\n",
      "0.37  /  0.49\n",
      "2136 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.87\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.17049970000000003\n",
      "\n",
      "model2 updated 958572\n",
      "0.17  /  0.49\n",
      "2021 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.61\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.35\n",
      "exploration rate :  -0.17099990000000004\n",
      "\n",
      "model2 updated 960730\n",
      "0.37  /  0.49\n",
      "2158 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.9\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.17149995\n",
      "\n",
      "model2 updated 962955\n",
      "0.19  /  0.49\n",
      "2225 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.09\n",
      "명령을 따랐는데 실패한 횟수 :  1\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.17199985\n",
      "\n",
      "model2 updated 965171\n",
      "0.38  /  0.49\n",
      "2216 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.19\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.17249990000000004\n",
      "\n",
      "model2 updated 967391\n",
      "0.38  /  0.49\n",
      "2220 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.17\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.17299990000000004\n",
      "\n",
      "model2 updated 969568\n",
      "0.37  /  0.49\n",
      "2177 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.04\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.17349990000000004\n",
      "\n",
      "model2 updated 971842\n",
      "0.13  /  0.49\n",
      "2274 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.18\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.39\n",
      "exploration rate :  -0.17399990000000004\n",
      "\n",
      "model2 updated 974060\n",
      "0.13  /  0.49\n",
      "2218 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.15\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.17449965\n",
      "\n",
      "model2 updated 976456\n",
      "0.41  /  0.49\n",
      "2396 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.38\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.41\n",
      "exploration rate :  -0.17499980000000004\n",
      "\n",
      "model2 updated 979241\n",
      "0.48  /  0.49\n",
      "2785 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.97\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.48\n",
      "exploration rate :  -0.17549980000000004\n",
      "\n",
      "model2 updated 982029\n",
      "0.01  /  0.49\n",
      "2788 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  5.1\n",
      "명령을 따랐는데 실패한 횟수 :  41\n",
      "평균 Reward :  0.46\n",
      "exploration rate :  -0.17599985\n",
      "\n",
      "model2 updated 984314\n",
      "0.38  /  0.49\n",
      "2285 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.32\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.38\n",
      "exploration rate :  -0.17649995000000002\n",
      "\n",
      "model2 updated 986158\n",
      "0.32  /  0.49\n",
      "1844 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.17\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.32\n",
      "exploration rate :  -0.17699990000000004\n",
      "\n",
      "model2 updated 987926\n",
      "0.31  /  0.49\n",
      "1768 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.0\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.31\n",
      "exploration rate :  -0.17749965\n",
      "\n",
      "model2 updated 989906\n",
      "0.34  /  0.49\n",
      "1980 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.53\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.34\n",
      "exploration rate :  -0.17799985000000002\n",
      "\n",
      "model2 updated 992061\n",
      "0.37  /  0.49\n",
      "2155 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.82\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.37\n",
      "exploration rate :  -0.17849975\n",
      "\n",
      "model2 updated 994129\n",
      "0.36  /  0.49\n",
      "2068 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.87\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.17899985000000002\n",
      "\n",
      "model2 updated 996237\n",
      "0.36  /  0.49\n",
      "2108 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  3.89\n",
      "명령을 따랐는데 실패한 횟수 :  0\n",
      "평균 Reward :  0.36\n",
      "exploration rate :  -0.17949995000000002\n",
      "\n",
      "model2 updated 998581\n",
      "0.13  /  0.49\n",
      "2344 번 시뮬레이션 결과\n",
      "평균 개선 step 수 :  4.46\n",
      "명령을 따랐는데 실패한 횟수 :  2\n",
      "평균 Reward :  0.4\n",
      "exploration rate :  -0.17999995000000002\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# main\n",
    "cur_data = random_load(train_df_list)\n",
    "cur_env = init_env(cur_data) # cur_step, cur_SFR, terminal_step\n",
    "# model.fit(np.asarray([np.ones(5)]),np.asarray([np.ones(5)]),verbose=0)\n",
    "\n",
    "# model = load_model('best_model(0).h5')\n",
    "# model.compile(optimizer = 'rmsprop', loss='mse', metrics=['mae'])\n",
    "model2.set_weights(model.get_weights())\n",
    "\n",
    "memory_D = []\n",
    "best_acc_reward = 0\n",
    "acc_step=0\n",
    "acc_reward = 0\n",
    "advanced_step = 0\n",
    "succeeded = 0\n",
    "failed = 0\n",
    "action_count = 0\n",
    "# with open('memory_D(1).pickle', 'rb') as f:\n",
    "#     memory_D = pickle.load(f)\n",
    "for j in range(1000000):\n",
    "#     print(j)\n",
    "\n",
    "#     acc_reward=0\n",
    "    \n",
    "\n",
    "    acc_step += 1\n",
    "    cur_data = random_load(train_df_list)\n",
    "    cur_env = init_env(cur_data)\n",
    "    terminal = False\n",
    "    # cur_state: [[현재 z 거리, 바로 전 z 거리, 현재 SFR, 바로 전 SFR, 기울기]]\n",
    "    cur_state = np.expand_dims(np.asarray([cur_data[0].iloc[0,1], cur_data[0].iloc[0,1], cur_env[1], cur_env[1],0]),axis=0)\n",
    "    reward = 0\n",
    "    cur_step = 0\n",
    "    episode_reward = 0\n",
    "    episode_step = 0\n",
    "    while terminal == False:\n",
    "        action = decide(model, cur_state)\n",
    "        cur_step += action\n",
    "#             print(cur_step, end = ' ')\n",
    "        past_state = cur_state\n",
    "        cur_env, cur_state, reward, memory_D = update_env(cur_data,cur_env,action, memory_D, cur_state)\n",
    "\n",
    "        episode_reward += reward\n",
    "        episode_step += 1\n",
    "        action_count += 1\n",
    "\n",
    "        if fit_count % 6 == 0:\n",
    "            model = model_fit(model, model2, memory_D)\n",
    "        if fit_count % 10000 == 0:\n",
    "            model2.set_weights(model.get_weights())\n",
    "#                 model2 = load_model('best_model(1).h5')\n",
    "#                 model2.compile(optimizer = 'rmsprop', loss='mse', metrics=['mae'])\n",
    "            print('\\nmodel2 updated', j)\n",
    "            print(round(acc_reward/action_count/(failed+1),2),' / ', round(best_acc_reward,2))\n",
    "            print(acc_step,'번 시뮬레이션 결과')\n",
    "\n",
    "            print('평균 개선 step 수 : ', round(advanced_step/acc_step,2))\n",
    "            print('명령을 따랐는데 실패한 횟수 : ', failed)\n",
    "            print('평균 Reward : ', round(acc_reward/action_count,2))\n",
    "            print('exploration rate : ', exploration_rate)\n",
    "\n",
    "            if acc_reward/action_count/(failed+1) >= best_acc_reward:\n",
    "                print('best model saved')\n",
    "                model.save('best_model(2).h5')\n",
    "\n",
    "                best_acc_reward = acc_reward/action_count/(failed+1)\n",
    "            acc_reward = 0\n",
    "            acc_step=0\n",
    "            advanced_step = 0\n",
    "            succeeded = 0\n",
    "            failed = 0\n",
    "            action_count = 0\n",
    "#         print('episode_reward : ', round(episode_reward,2))\n",
    "#         print('스탭 개선 수 : ', cur_step - episode_step,'\\n')\n",
    "    advanced_step += cur_step - episode_step\n",
    "    acc_reward += episode_reward\n",
    "    exploration_rate = 0.05-0.05*fit_count/10**6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             with open('memory_D(1).pickle', 'wb') as f:\n",
    "#                 pickle.dump(memory_D, f)\n",
    "#             if best_advanced_step > bestofbest_step:\n",
    "#                 bestofbest_step = best_advanced_step\n",
    "#                 model.save('bestofbest_model'+str(round(bestofbest_step,1))+'.h5')\n",
    "#                 print('best of best model updated\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 11000 12000 13000 14000 15000 \n",
      "모든 데이터 시뮬레이션 결과 정리\n",
      "평균 개선 step 수 :  5.168292529422871\n",
      "개선율 :  39.823229362101316 %\n",
      "실패율 :  0.03776197369249166 %\n",
      "명령을 따랐는데 실패한 횟수 :  6\n",
      "평균 누적 Reward :  1.68 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "############## 저장된 모델 불러오는 부분########\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('best_model(2).h5')\n",
    "model.compile(optimizer = 'rmsprop', loss='mse', metrics=['mae'])\n",
    "###############################################\n",
    "\n",
    "advanced_step=0\n",
    "acc_reward=0\n",
    "failed=0\n",
    "acc_origin_step = 0\n",
    "acc_episode_step=0\n",
    "for k in range(len(test_df_list)):\n",
    "    if k%1000==0:\n",
    "        print(k,end=' ')\n",
    "    cur_data = select_load(test_df_list,k)\n",
    "    acc_origin_step += cur_data[1]\n",
    "    cur_env = init_env(cur_data)\n",
    "    terminal = False\n",
    "    # cur_state: [[현재 z 거리, 바로 전 z 거리, 현재 SFR, 바로 전 SFR, 기울기]]\n",
    "    cur_state = np.expand_dims(np.asarray([cur_data[0].iloc[0,1], cur_data[0].iloc[0,1], cur_env[1], cur_env[1],0]),axis=0)\n",
    "    reward = 0\n",
    "    cur_step = 0\n",
    "    episode_reward = 0\n",
    "    episode_step = 0\n",
    "    \n",
    "    while terminal == False:\n",
    "        action = best_decide(model, cur_state)\n",
    "        cur_step += action\n",
    "#             print(cur_step, end = ' ')\n",
    "        past_state = cur_state\n",
    "        cur_env, cur_state, reward, memory_D = update_env(cur_data,cur_env,action, memory_D, cur_state)\n",
    "        episode_reward += reward\n",
    "        episode_step += 1\n",
    "#         print('episode_reward : ', round(episode_reward,2))\n",
    "#         print('스탭 개선 수 : ', cur_step - episode_step,'\\n')\n",
    "    advanced_step += cur_step - episode_step\n",
    "    acc_episode_step += episode_step\n",
    "    acc_reward += episode_reward\n",
    "print('\\n모든 데이터 시뮬레이션 결과 정리')\n",
    "print('평균 개선 step 수 : ', advanced_step/len(test_df_list))\n",
    "print('개선율 : ', 100*acc_episode_step/acc_origin_step, '%')\n",
    "print('실패율 : ', 100*failed/len(test_df_list),'%')\n",
    "print('명령을 따랐는데 실패한 횟수 : ', failed)\n",
    "print('평균 누적 Reward : ', round(acc_reward/len(test_df_list),2),'\\n')\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 아래는 데이터 전처리하였던 코드 (정리 안된 상태)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "idx=[]\n",
    "for i in range(len(df_list)):\n",
    "    if str(type(df_list[i].loc[0,'CentSFR 0.7'])) != \"<class 'numpy.float64'>\":\n",
    "        idx.append(i)\n",
    "        count+=1\n",
    "        print(i)\n",
    "        print(df_list[i])\n",
    "#         if len(df_list[i])<10:\n",
    "#             print('뷁',i)\n",
    "#         if len(df_list[i])<10:\n",
    "#             count+=1\n",
    "#             print(i, df_list[i]['CentSFR 0.7'].argmax())\n",
    "#             print(df_list[i])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-de5e194e3d5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "df_list[idx[0]].index[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for i in idx:\n",
    "    tmp_df = df_list[i-k]\n",
    "    tmp_idx=[]\n",
    "    for j in range(len(tmp_df)):\n",
    "        \n",
    "        if tmp_df.index[j]==0:\n",
    "            tmp_idx.append(j)\n",
    "    for j in range(len(tmp_idx)):\n",
    "        if j != len(tmp_idx)-1:\n",
    "            df_list.append(tmp_df.iloc[tmp_idx[j]:tmp_idx[j+1],:])\n",
    "        else:\n",
    "            df_list.append(tmp_df.iloc[tmp_idx[j]:,:])\n",
    "    df_list.pop(i-k)\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_list)):\n",
    "    if df_list[i].index[0]!=0:\n",
    "        print(i)\n",
    "        print(df_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list.pop(48503)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(idx)):\n",
    "    if len(df_list[idx[i]].loc[0,:]) != 2:\n",
    "        print(len(df_list[idx[i]].loc[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[4316].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[9313].iloc[2:,2].argmax()+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[9313].iloc[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[1062]['CentSFR 0.7'].iloc[2:].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[1062]['CentSFR 0.7'].iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(memory_D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
